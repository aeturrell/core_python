{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Project 9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started in Python\n",
    "\n",
    "Head to the \"Getting Started in Python\" page for help and advice on setting up a Python session to work with. Remember, you can run any page from this book as a *notebook* by downloading the relevant file from this [repository](https://github.com/aeturrell/core_python) and running it on your own computer. Alternatively, you can run pages online in your browser over at [Binder](https://mybinder.org/v2/gh/aeturrell/core_python/HEAD)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Settings\n",
    "\n",
    "Let's import the packages we'll need and also configure the settings we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pingouin as pg\n",
    "from lets_plot import *\n",
    "\n",
    "LetsPlot.setup_html(no_js=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.1\n",
    "\n",
    "**Importing data into Python**\n",
    "\n",
    "Ensure that the Excel file you downloaded is in a sub-directory of your working directory called \"data\".\n",
    "\n",
    "Before importing the data, open it in Excel to look at its structure. You can see there are three tabs: ‘Data dictionary’, ‘All households’, and ‘Got loan’. We will import them into separate dataframes (data_dict, all_hh, and got_l respectively). We import the ‘Data dictionary’ so that we do not have to return to the Excel spreadsheet.\n",
    "\n",
    "Also note that there are a lot of empty cells, which is how missing data is coded in Excel (but not in Python). In the `pd.read_excel` function, the default is already that empty cell are read as NA, so we don't need to specify this. Note that this particular Excel file has some file issues that mean **pandas** will warn you about an \"unknown extension\": an Excel file is actually a bundle of files tied up to look like one file, and what's happened here is that **pandas** doesn't recognise one of the files in the bundle—but we can still happily get at the data we need in the worksheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.read_excel(\n",
    "    Path(\"data/doing-economics-working-in-excel-project-9-datafile.xlsx\"),\n",
    "    sheet_name=\"Data dictionary\",\n",
    ")\n",
    "\n",
    "all_hh = pd.read_excel(\n",
    "    Path(\"data/doing-economics-working-in-excel-project-9-datafile.xlsx\"),\n",
    "    sheet_name=\"All households\",\n",
    ")\n",
    "\n",
    "got_l = pd.read_excel(\n",
    "    Path(\"data/doing-economics-working-in-excel-project-9-datafile.xlsx\"),\n",
    "    sheet_name=\"Got loan\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s look at the variable types `all_hh` and `got_l` using the `.info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to ensure that all variables we expect to be numerical (numbers) show either int or float as their 'Dtype', and in this case, they are. You can see that there are many variables that are coded as object variables because they are text (for example gender or region), but since we can use these variables to group data by category, we will use `.astype(\"category\")` to change them into categorical variables for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of converting each object variable to a factor variable individually, we can use the `select_dtypes` method to find *all* columns that are currently of type object and then convert those columns specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = all_hh.select_dtypes(\"object\").columns\n",
    "all_hh[cols] = all_hh[cols].astype(\"category\")\n",
    "\n",
    "cols = got_l.select_dtypes(\"object\").columns\n",
    "got_l[cols] = got_l[cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making use of `.info()` will now show you that the remaining object columns have been \"recast\" to be of data type \"category\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.2\n",
    "\n",
    "**Creating summary tables**\n",
    "\n",
    "In order to get the proportions of households in each region living in large towns, small towns, or rural areas (encoded in the variable `rural`), we use the `pd.crosstab` function to create a cross-tabulation. Without any further options, `pd.crosstab` would produce counts of households in the respective regions and area types. However, we can pass a keyword argument, `normalize`, to turn the counts into proportions by, for example, rows or columns.\n",
    "\n",
    "In the below, we use `normalize=\"index\"` to ensure that each row sums to one. We also use `.round(3)` to limit the number of decimal places that are saved in the output data frame.\n",
    "\n",
    "Remember that if you ever want to know more about a function, you can hover over it in Visual Studio Code and see its options, including the keyword arguments it takes. Or you can run `help(function-name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_one = pd.crosstab(all_hh[\"region\"], all_hh[\"rural\"], normalize=\"index\").round(3)\n",
    "stab_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may not always want a cross-tab. For the case where we simply want an overall percentage, we can use \n",
    "\n",
    "Let’s use a similar approach to calculate the percentage of households with women as head of the family (encoded in the variable `gender`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_two = all_hh[\"gender\"].value_counts(normalize=True).round(3)\n",
    "stab_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, 30.4% of households have a head of the family who is a woman.\n",
    "\n",
    "We need to provide summary statistics for a range of variables. Most of these variables are numeric variables, but one, gender, is a categorical variable. We can distinguish these types using the `.select_dtypes` method.\n",
    "\n",
    "There are a few different ways to get summary statistics on a data frame. **pandas** has a built-in method called `.describe` which produces different information depending on whether the given columns are numeric or not. Here it is running on just numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh.select_dtypes(\"number\").describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use it on a categorical variable, `gender`, we get information relevant to that type of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh[\"gender\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are, of course, lots of different types of data. A more powerful summary of a data frame is provided by a packaged called **skimpy** (which you can install by running `pip install skimpy` on the command line). Here is **skimpy**'s `skim` function applied to `all_hh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import skim\n",
    "\n",
    "skim(all_hh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see lots of information on both the categorical and numeric data types!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.3\n",
    "\n",
    "**Making frequency tables for loan applications and outcomes**\n",
    "\n",
    "The easiest way to make a frequency table is to use the `pd.crosstab` function. Note that we use the `dropna=False` option (and \"All\" minus the sum of \"No\" and \"Yes\" gives the number of NAs), and the `margins=True` option to give those totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_three = pd.crosstab(\n",
    "    all_hh[\"did_not_apply\"], all_hh[\"loan_rejected\"], dropna=False, margins=True\n",
    ")\n",
    "stab_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do some data cleaning and re-examine the table. We:\n",
    "\n",
    "- exclude the households that indicated that they did not apply for a loan, but also indicated that they were refused a loan. This results in excluding more than 10% of households that indicated that they were refused a loan, but the answer is nonsensical. We will use the `~` operator, which means \"not\" the logic that follows.\n",
    "- We shall also remove all observations that have missing data for any of these two questions (by using the implicit default value of `dropna=True`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c = all_hh.loc[\n",
    "    ~(\n",
    "        (all_hh[\"loan_rejected\"] == \"Yes\")\n",
    "        & (all_hh[\"did_not_apply\"] == \"Did not apply\")\n",
    "    ),\n",
    "    :,\n",
    "].copy()\n",
    "stab_four = pd.crosstab(\n",
    "    all_hh_c[\"did_not_apply\"], all_hh_c[\"loan_rejected\"], margins=True, normalize=\"all\"\n",
    ").round(3)\n",
    "stab_four"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we used the classic syntax for accessing rows and columns, `.loc[rows, columns]`. Because we wanted *all* columns, we used `:`. We also created a new set of data that we'll follow around as `all_hh_c` by using `.copy()`. Without this, any modifications we made to `all_hh_c` would also go back to `all_hh`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.4\n",
    "\n",
    "**Creating variables to classify households**\n",
    "\n",
    "Let’s first create the `hh_status` variable. We set the values of `hh_status` to \"not applied\", then use logical indexing to change all entries where households applied for a loan (`all_hh_c[\"did_not_apply\"] == \"Applied\"`) and were accepted (`all_hh_c[\"loan_rejected\"] == \"No\"`) to \"successful\", and households who were denied (`all_hh_c[\"loan_rejected\"] == \"Yes\"`) to \"denied\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the default category and creates the new column\n",
    "all_hh_c[\"hh_status\"] = \"not applied\"\n",
    "\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"did_not_apply\"] == \"Applied\") & (all_hh_c[\"loan_rejected\"] == \"No\"),\n",
    "    \"hh_status\",\n",
    "] = \"successful\"\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"did_not_apply\"] == \"Applied\") & (all_hh_c[\"loan_rejected\"] == \"Yes\"),\n",
    "    \"hh_status\",\n",
    "] = \"denied\"\n",
    "\n",
    "# Change from a string variable to a categorical variable\n",
    "all_hh_c[\"hh_status\"] = all_hh_c[\"hh_status\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the frequencies of the different outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"hh_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will continue by using the same steps to make the `discouraged_borrower` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the default category and creates the new column\n",
    "all_hh_c[\"discouraged_borrower\"] = \"No\"\n",
    "\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"reason_not_apply1\"] == \"Believe Would Be Refused\"),\n",
    "    \"discouraged_borrower\",\n",
    "] = \"Yes\"\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"reason_not_apply2\"] == \"Believe Would Be Refused\"),\n",
    "    \"discouraged_borrower\",\n",
    "] = \"Yes\"\n",
    "\n",
    "# Change from a string variable to a categorical variable\n",
    "all_hh_c[\"discouraged_borrower\"] = all_hh_c[\"discouraged_borrower\"].astype(\"category\")\n",
    "\n",
    "all_hh_c[\"discouraged_borrower\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the `credit_constrained` variable, we use the `.cat.categories` property to check all the possible answers to the `reason_not_apply1` variable. We store these answers in the object `sel_ans`. (To convert from an index, a special type of **pandas** object, to a simple Python list, we put the expression on the right-hand side within a `list(..)`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_ans = list(all_hh_c[\"reason_not_apply1\"].cat.categories)\n",
    "sel_ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these reasons, only reasons 4 (Have Adequate Farm) and 7 (Other) do not lead to a conclusion that a household is credit constrained, so we remove them from `sel_ans`. Note that this numbering starts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_ans.remove(\"Have Adequate Farm\")\n",
    "sel_ans.remove(\"Other (Specify)\")\n",
    "sel_ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Households that did not provide any reasons are classified as *not* credit constrained. We'll take this as our default category and use it to create the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"credit_constrained\"] = \"No\"\n",
    "\n",
    "all_hh_c.loc[all_hh_c[\"reason_not_apply1\"].isin(sel_ans), \"credit_constrained\"] = \"Yes\"\n",
    "all_hh_c.loc[all_hh_c[\"reason_not_apply2\"].isin(sel_ans), \"credit_constrained\"] = \"Yes\"\n",
    "\n",
    "# let's turn this into a categorical variable\n",
    "all_hh_c[\"credit_constrained\"] = all_hh_c[\"credit_constrained\"].astype(\"category\")\n",
    "all_hh_c[\"credit_constrained\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of `.isin` in the selection criterion is a very useful programming technique that you can use to select data according to a list of variables. In this case, `sel_ans` contains all the answers that we associate with a credit-constrained household.\n",
    "\n",
    "`all_hh_c[\"reason_not_apply1\"].isin(sel_ans)` gives an outcome of `True` if the variable taken by an entry in the column `reason_not_apply1` is one of the values in `sel_ans`. In that case, it sets the value of `credit_constrained` to \"Yes\" for those observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_four = pd.crosstab(\n",
    "    all_hh_c[\"credit_constrained\"],\n",
    "    all_hh_c[\"discouraged_borrower\"],\n",
    "    margins=True,\n",
    "    normalize=\"all\",\n",
    ").round(3)\n",
    "stab_four"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the frequencies of the different reasons to not apply, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"reason_not_apply1\"].value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"reason_not_apply2\"].value_counts(normalize=True).round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.5\n",
    "\n",
    "**Making frequency tables to compare proportions**\n",
    "\n",
    "Some of the data is in the `all_hh` dataset, while the rest is in the `got_l` dataset, both of which we imported in Python Walkthrough 9.1. We will combine that information into one new dataset called `loan_data`, which we then use to produce the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_all_hh_c = all_hh_c.loc[all_hh_c[\"hh_status\"].isin([\"successful\", \"denied\"])]\n",
    "\n",
    "pd.crosstab(\n",
    "    sel_all_hh_c[\"loan_purpose\"], sel_all_hh_c[\"hh_status\"], margins=True, dropna=False\n",
    ").round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals a particular feature of the data: it doesn't contain as much useful information as we'd like! Most succesful loans actually have \"NA\" in the box for loan purpose (bar one which has \"Expanding Business\"). The cross-tab above shows us that there were 1363 successful loans but only one with a purpose.\n",
    "\n",
    "There is more useful information on loan purpose in the `got_l` data, so we will extract the `loan_purpose` variable for unsuccessful households from the `all_hh_c` dataset, and the equivalent information for successful loaners from the `got_l` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unsuccessful households from all_hh_c\n",
    "loan_no = all_hh_c.loc[all_hh_c[\"hh_status\"] == \"denied\", [\"loan_purpose\", \"hh_status\"]]\n",
    "\n",
    "# Select loan purpose for successful households from gotL\n",
    "loan_yes = got_l.loc[got_l[\"got_loan\"] == \"Yes\", [\"loan_purpose\"]]\n",
    "loan_yes[\"hh_status\"] = \"successful\"\n",
    "\n",
    "# combine the data through concatenation\n",
    "loan_data = pd.concat([loan_yes, loan_no])\n",
    "\n",
    "# let's look at the values\n",
    "pd.crosstab(\n",
    "    loan_data[\"loan_purpose\"], loan_data[\"hh_status\"], normalize=\"columns\"\n",
    ").round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.6\n",
    "\n",
    "**Calculating differences in household characteristics**\n",
    "\n",
    "Here we show how to get average characteristics conditional on `\"hh_status\"` using the mean function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the number of observations in each category\n",
    "all_hh_c[\"hh_status\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at mean household size conditional on credit status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c.groupby(\"hh_status\").mean(numeric_only=True)[\"hhsize\"].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the mean max_education of household head by credit status?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c.groupby(\"hh_status\").mean(numeric_only=True)[\"max_education\"].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can use cross-tabs to see the number of observations in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    all_hh_c[\"rural\"],\n",
    "    all_hh_c[\"hh_status\"],\n",
    ").round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get even more breakdowns, you can add more variables to the \"groupby\".\n",
    "\n",
    "Let's see an example with mean household size by the other variables rural and credit status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c.groupby([\"hh_status\", \"rural\"]).mean(numeric_only=True)[\"hhsize\"].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, here, the number of working age adults by the rural and credit variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c.groupby([\"hh_status\", \"rural\"]).mean(numeric_only=True)[\n",
    "    \"working_age_adults\"\n",
    "].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.7\n",
    "\n",
    "**Calculating confidence intervals and adding them to a chart**\n",
    "\n",
    "To repeat the same set of calculations for a list of variables, first we create a list of these variables (called `sel_var`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_var = [\n",
    "    \"age\",\n",
    "    \"max_education\",\n",
    "    \"number_assets\",\n",
    "    \"hhsize\",\n",
    "    \"young_children\",\n",
    "    \"working_age_adults\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `age` variable as an example, removing the 'did not apply' entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_5 = (\n",
    "    all_hh_c.groupby(\"hh_status\")[\"age\"]\n",
    "    .agg({\"mean\", \"count\", \"std\"})\n",
    "    .drop(\"not applied\")\n",
    "    .round(2)\n",
    ")\n",
    "stats_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the t-test function from the **pingouin** package to calculate the difference between the successful group (`sel_success`) and the denied borrowers (`sel_denied`).\n",
    "\n",
    "**pingouin**'s t-test function is called `ttest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Select the age variable (aka sel_var[0]) for successful and\n",
    "# denied borrowers\n",
    "sel_success = all_hh_c.loc[all_hh_c[\"hh_status\"] == \"successful\", sel_var[0]]\n",
    "sel_denied = all_hh_c.loc[all_hh_c[\"hh_status\"] == \"denied\", sel_var[0]]\n",
    "\n",
    "# do the t-test. Default confidence is 0.95, but include it here to be explicit\n",
    "pg.ttest(x=sel_success, y=sel_denied, confidence=0.95).round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this test indicates whether the ages of the two groups are statistically different (here, they are).\n",
    "\n",
    "We will now do this for all variables of interest and save the difference in means and the confidence interval values in a dataframe so we can plot this information.\n",
    "\n",
    "To make this easier, we'll write a function that:\n",
    "\n",
    "- takes the name of the variable of interest as function\n",
    "- selects successful and unsuccessful applicants, and performs a t-test on that variable (like we already did for age)\n",
    "- returns the answers (the difference in means and the upper and lower confidence limits) in a format useful for populating a dataframe of results\n",
    "\n",
    "We will create an empty dataframe to populate with this info and then run the whole thing in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ttest_and_mean_for_variable(dataframe_variable, selected_variable):\n",
    "    \"\"\"Given a dataframe with loan statuses encoded by a \"hh_status\" column\n",
    "    with values of \"successfull\" and \"denied\", and columns that have other\n",
    "    relevant characteristics, this function returns the mean difference between\n",
    "    the successful and denied households according to the characteristic given\n",
    "    by the 'selected_variable'.\n",
    "\n",
    "    Args:\n",
    "        dataframe_name (pandas dataframe): Data containing loan outcomes.\n",
    "        selected_variable (string): Name of other characteristic.\n",
    "\n",
    "    Returns:\n",
    "        list (floats): Mean difference, low limit conf int, high limit conf int\n",
    "    \"\"\"\n",
    "    # Select the variable for successful and\n",
    "    # denied borrowers\n",
    "    sel_success = dataframe_variable.loc[\n",
    "        dataframe_variable[\"hh_status\"] == \"successful\", selected_variable\n",
    "    ]\n",
    "    sel_denied = dataframe_variable.loc[\n",
    "        dataframe_variable[\"hh_status\"] == \"denied\", selected_variable\n",
    "    ]\n",
    "\n",
    "    # do the t-test. Default confidence is 0.95, but include it here to be explicit\n",
    "    pg.ttest(x=sel_success, y=sel_denied, confidence=0.95).round(3)\n",
    "\n",
    "    mean_difference = sel_success.mean() - sel_denied.mean()\n",
    "    mean_low, mean_high = (\n",
    "        pg.ttest(x=sel_success, y=sel_denied, confidence=0.95)\n",
    "        .round(3)[\"CI95%\"]\n",
    "        .explode()\n",
    "        .to_list()\n",
    "    )\n",
    "    return mean_difference, mean_low, mean_high\n",
    "\n",
    "\n",
    "# create an empty dataframe for the results\n",
    "data_to_plot = pd.DataFrame()\n",
    "\n",
    "# Now we can loop through the variables\n",
    "for this_variable in sel_var:\n",
    "    mean_diff, low, high = get_ttest_and_mean_for_variable(all_hh_c, this_variable)\n",
    "    temp_data = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"var_name\": this_variable,\n",
    "            \"mean_difference\": mean_diff,\n",
    "            \"conf_low\": low,\n",
    "            \"conf_high\": high,\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    ).T\n",
    "    data_to_plot = pd.concat([temp_data, data_to_plot], axis=0)\n",
    "\n",
    "# give different rows different index numbers (dropping old index)\n",
    "data_to_plot = data_to_plot.reset_index(drop=True)\n",
    "data_to_plot.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the chart using **lets-plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        data_to_plot.reset_index(),\n",
    "        aes(\n",
    "            x=\"var_name\",\n",
    "            y=\"mean_difference\",\n",
    "            fill=\"var_name\",\n",
    "        ),\n",
    "    )\n",
    "    + geom_bar(stat=\"identity\", show_legend=False, color=\"black\", alpha=0.6)\n",
    "    + geom_errorbar(\n",
    "        aes(ymin=\"conf_low\", ymax=\"conf_high\", color=\"var_name\"),\n",
    "        size=2,\n",
    "        show_legend=False,\n",
    "    )\n",
    "    + coord_flip()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9.2 Bar chart showing difference in household characteristics for successful and denied borrowers.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.8\n",
    "\n",
    "**Calculating conditional means**\n",
    "\n",
    "We are interested in the means of a range of variables for different subgroups. Two subgroups are mutually exclusive (`hh_status` == \"successful\" and `hh_status` == \"denied\"), while the others (`credit_constrained` == \"yes\" and `discouraged_borrower` == \"yes\") are partially overlapping subgroups of the data. Our strategy is to create a temporary dataframe (`sel_all_hh_c`) that only contains the relevant observations and the relevant variables. Then we can calculate the required means using **pandas** built-in `.mean` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables we are interested in\n",
    "sel_var = [\n",
    "    \"age\",\n",
    "    \"max_education\",\n",
    "    \"number_assets\",\n",
    "    \"hhsize\",\n",
    "    \"young_children\",\n",
    "    \"working_age_adults\",\n",
    "]\n",
    "\n",
    "sel_all_hh_c = all_hh_c.loc[all_hh_c[\"hh_status\"] == \"successful\", sel_var]\n",
    "\n",
    "print(f\"Successful, n = {len(sel_all_hh_c)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the means of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_all_hh_c.mean(axis=\"index\").round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same operation with \"denied\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_all_hh_c = all_hh_c.loc[all_hh_c[\"hh_status\"] == \"denied\", sel_var]\n",
    "\n",
    "print(f\"Denied, n = {len(sel_all_hh_c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can re-calculate the conditional means based on this cut too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_all_hh_c.mean(axis=\"index\").round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use similar methods to look at discouraged and credit constrained households."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.9\n",
    "\n",
    "**Data cleaning and summarising loan characteristics**\n",
    "\n",
    "We start by cleaning up the loan dates. We have information on start month and year as well as end month and year. Let's look at these in turn. The structure of the dataframe `got_l.info()` indicates that the start and end year are numeric variables, but the months are factor variables with month names (for example 'April').\n",
    "\n",
    "Let's first look at the years by creating a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(got_l, aes(x=\"loan_endyear\", y=\"loan_startyear\"))\n",
    "    + geom_point(size=6)\n",
    "    + labs(\n",
    "        title=\"Loan start and end year\",\n",
    "    )\n",
    "    + scale_x_continuous(format=\"\")\n",
    "    + scale_y_continuous(format=\"\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9.3 Scatterplot showing loan start and end year.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are three observations that have very low (< 500) start or end year values, which does not make sense. We will replace these with 'pd.NA', but leave the original data untouched and create a new dataset called `got_l_c`, where the ‘c’ indicates cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c = got_l.copy()\n",
    "got_l_c.loc[\n",
    "    (got_l_c[\"loan_startyear\"] < 500) | (got_l_c[\"loan_endyear\"] < 500),\n",
    "    [\"loan_startyear\", \"loan_endyear\"],\n",
    "] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(got_l_c, aes(x=\"loan_endyear\", y=\"loan_startyear\"))\n",
    "    + geom_point()\n",
    "    + labs(\n",
    "        title=\"Loan start and end year\",\n",
    "    )\n",
    "    + scale_x_continuous(format=\"\")\n",
    "    + scale_y_continuous(format=\"\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9.4 Revised scatterplot showing loan start and end year without outliers.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the top left corner, there is a loan with the start year (2006) after the end year (2003). Clearly this is incorrect, so we should remove this observation when analysing loan periods. However, we wait until we have combined the years with the months as there may be more observations with this issue.\n",
    "\n",
    "Also, we can only see a small number of points because there are many identical observations (for example startyear of 2006 and endyear of 2006). To see these points you can add `position=position_jitter()` to the **lets-plot** plotting command. Hover your mouse over the function within an integrated development environment to see what `position_jitter()` does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(got_l_c, aes(x=\"loan_endyear\", y=\"loan_startyear\"))\n",
    "    + geom_point(position=position_jitter())\n",
    "    + labs(\n",
    "        title=\"Loan start and end year\",\n",
    "    )\n",
    "    + scale_x_continuous(format=\"\")\n",
    "    + scale_y_continuous(format=\"\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s look at the values in `loan_startmonth`. We'll keep any null values because we're interested in missing observations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c[\"loan_startmonth\"].value_counts(dropna=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all looks fine apart from the NaN (not a number) entries; what about the end months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c[\"loan_endmonth\"].value_counts(dropna=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things are noteworthy here: there are many \"NaN\" entries, and there is an entry called \"Pagume\". As described in the task, \"Pagume\" can be approximated by September. Let's recode that, and the nans to \"Missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c.loc[got_l_c[\"loan_endmonth\"] == \"Pagume\", \"loan_endmonth\"] = \"September\"\n",
    "for col in [\"loan_startmonth\", \"loan_endmonth\"]:\n",
    "    # add a 'missing' category\n",
    "    got_l_c[col] = got_l_c[col].cat.add_categories(\"missing\")\n",
    "    # fill na with 'missing'\n",
    "    got_l_c[col] = got_l_c[col].fillna(\"missing\")\n",
    "\n",
    "for col in [\"loan_startyear\", \"loan_endyear\"]:\n",
    "    # first convert to integer to remove .0 at end\n",
    "    # then to string, with missing replacing nans\n",
    "    got_l_c[col] = got_l_c[col].astype(\"Int64\").astype(\"string\").fillna(\"missing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the end months now have sensible entries for the valid rows.\n",
    "\n",
    "Let's now calculate the length of the loan; in other words, the number of days between start and end day. **pandas** has very powerful functionality for dates and times. Our first step is to create a new variables that combines months and years together. We can do this by casting (using `.astype`) columns as strings and then using `pd.to_datetime`. We have to coerce any NaN values otherwise we will get an error.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(\n",
    "    got_l_c[\"loan_startmonth\"].astype(\"str\") + \"-\" + got_l_c[\"loan_startyear\"],\n",
    "    errors=\"coerce\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is assumed that we're counting from the first day of each month. `pd.to_datetime` is converting whatever we feed it to the closest *datetime* that is similar. A *datetime* is a special type of variable in computer science: it encodes year, month, day, hours, minutes and seconds. Timing is important so this variable type is incredibly useful!\n",
    "\n",
    "`pd.to_datetime` will always do a best guess based on what you put in. See what happens if you try putting in a string like \"15-March-2004\" instead. If you *don't* want your date to be at the start of the month, you can 'add' the month end on to the date using `+ pd.offsets.MonthEnd()`.\n",
    "\n",
    "Now let's put the months into the dataframe (using the default of month start):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c[\"loan_start_datetime\"] = pd.to_datetime(\n",
    "    got_l_c[\"loan_startmonth\"].astype(\"str\") + \"-\" + got_l_c[\"loan_startyear\"],\n",
    "    errors=\"coerce\",\n",
    ")\n",
    "got_l_c[\"loan_end_datetime\"] = pd.to_datetime(\n",
    "    got_l_c[\"loan_endmonth\"].astype(\"str\") + \"-\" + got_l_c[\"loan_endyear\"],\n",
    "    errors=\"coerce\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assess how much missing data we have (as a proportion of the categories we're interested in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_nans = (\n",
    "    got_l_c.isna()\n",
    "    .agg([\"sum\", \"count\"])\n",
    "    .loc[:, [\"loan_start_datetime\", \"loan_end_datetime\"]]\n",
    "    .T\n",
    ")\n",
    "summary_nans[\"pct\"] = 100 * summary_nans[\"sum\"] / summary_nans[\"count\"]\n",
    "summary_nans.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have start and end dates in datetime formats. We need only compute the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c[\"loan_length\"] = got_l_c[\"loan_end_datetime\"] - got_l_c[\"loan_start_datetime\"]\n",
    "got_l_c[\"loan_length\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following:\n",
    "\n",
    "- we are missing some loans that didn't have start or end dates, which have appeared as 'NaT', ie 'Not a Time'\n",
    "- some loan lengths are negative because the recorded end date is before the start date (it could be that the two dates were switched when the data was entered into the system)\n",
    "\n",
    "These data problems are unfortunate but a common feature of real-life empirical work, and you will have to be on the lookout for them!\n",
    "\n",
    "As required in Question 1, we will create two variants of the `loan_length` variable: one where we assign missing values to all observations that have negative `loan_length`, and one where we assume that the problem was the switching of start and end date, so we transform all loan lengths to positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the NaT version\n",
    "got_l_c[\"loan_length_na\"] = got_l_c[\"loan_length\"].copy()\n",
    "# set anything less than 0 days to NaT\n",
    "got_l_c.loc[got_l_c[\"loan_length_na\"] < pd.Timedelta(0, \"d\"), \"loan_length_na\"] = pd.NaT\n",
    "\n",
    "# create the absolute version\n",
    "got_l_c[\"loan_length_abs\"] = got_l_c[\"loan_length\"].copy()\n",
    "# set anything less than 0 days to its reverse\n",
    "got_l_c.loc[\n",
    "    got_l_c[\"loan_length_abs\"] < pd.Timedelta(0, \"d\"), \"loan_length_abs\"\n",
    "] = -got_l_c.loc[got_l_c[\"loan_length_abs\"] < pd.Timedelta(0, \"d\"), \"loan_length_abs\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the `long_term` variable and look at the number of long-term loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c.loc[got_l_c[\"loan_length_abs\"].isna(), \"long_term\"] = pd.NA\n",
    "got_l_c.loc[got_l_c[\"loan_length_abs\"] > pd.Timedelta(365, \"d\"), \"long_term\"] = True\n",
    "got_l_c.loc[got_l_c[\"loan_length_abs\"] < pd.Timedelta(365, \"d\"), \"long_term\"] = False\n",
    "\n",
    "got_l_c[\"long_term\"].value_counts(dropna=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore have about 23% loans that are long-term (only looking at loans for which we do have date information)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.10\n",
    "\n",
    "**Making summary tables and calculating correlations**\n",
    "\n",
    "To make summary tables, we use the `skim` function from the **skimpy** package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import skim\n",
    "\n",
    "skim(got_l_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c[\"loan_length_abs\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be helpful to look at loan amounts and interest rate graphically, for example in a scatterplot. We'll use the **lets-plot** package for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(got_l_c, aes(x=\"loan_amount\", y=\"loan_interest\"))\n",
    "    + geom_point(size=3)\n",
    "    + labs(\n",
    "        title=\"Loan start and end year\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9.5 Scatterplot showing loan amounts and interest payments.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One large loan (top right corner) dominates this graph. Let's exclude observations with a loan amount larger than 200,000 from the plotted area of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(got_l_c, aes(x=\"loan_amount\", y=\"loan_interest\"))\n",
    "    + geom_point(size=3)\n",
    "    + labs(\n",
    "        title=\"Loan start and end year\",\n",
    "    )\n",
    "    + ylim(0, 3e4)\n",
    "    + xlim(0, 2e5)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9.6 Revised scatterplot showing loan amounts and interest payments without outliers.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly we can see many zero interest loans. Now we will calculate the interest rate as `loan_interest`/`loan_amount`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c[\"interest_rate\"] = got_l_c[\"loan_interest\"] / got_l_c[\"loan_amount\"]\n",
    "got_l_c[\"interest_rate\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum interest rate is 200 (in other words 20,000%), which does not make sense and could be due to a data entry error. Making another scatterplot can also identify extreme values for loan amounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(got_l_c, aes(x=\"loan_amount\", y=\"interest_rate\"))\n",
    "    + geom_point(size=3)\n",
    "    + labs(\n",
    "        title=\"Loan amounts and interest rates\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9.7 Scatterplot identifying extreme values for loan amounts.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another scatterplot, excluding the observation with the extremely high interest rate and only looking at small loan amounts (<1,000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(got_l_c, aes(x=\"loan_amount\", y=\"interest_rate\"))\n",
    "    + geom_point(size=3)\n",
    "    + labs(\n",
    "        title=\"Loan amounts and interest rates\",\n",
    "    )\n",
    "    + xlim(0, 1e3)\n",
    "    + ylim(0, 5)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9.8 Scatterplot excluding extremely high interest rate and including only small loan amounts.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can see that there are many zero interest loans. From the summary statistics above, we can see that the median interest rate is 0, which implies that at least 50% of loans have a zero interest rate. The following code calculates that percentage precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_interest_rate = (\n",
    "    100 * (got_l_c[\"interest_rate\"] == 0).sum() / got_l_c[\"interest_rate\"].count()\n",
    ")\n",
    "\n",
    "print(f\"The number of loans with a rate of zero is {num_zero_interest_rate.round(2)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate statistics conditional on whether a loan is long term or not. Before we do this, we will remove the observation with the very extreme interest rate (20,000%) from our `got_l_c` dataset (but not from the original `got_l` dataset). That observation has a loan amount of 1 and an interest payment of 200, which is probably a data entry mistake. There is another extreme observation (with a loan amount of 30,000,000), but there is no indication that this observation is misrecorded as there is a significant interest payment for this loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l_c = got_l_c.loc[got_l_c[\"interest_rate\"] < 200, :]\n",
    "got_l_c.groupby(\"long_term\")[\"interest_rate\"].agg(\n",
    "    [\"mean\", \"std\", \"min\", \"max\", \"median\", \"count\"]\n",
    ").round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the mean and median interest rate are higher for long-term loans. You can adapt the code above to calculate statistics for the `loan_amount` variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate correlations between interest rates and household characteristics. We store the correlation coefficients in a matrix (array of rows and columns) called `m_corr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_corr = got_l_c.loc[\n",
    "    ~got_l_c[\"interest_rate\"].isna(),\n",
    "    [\n",
    "        \"age\",\n",
    "        \"max_education\",\n",
    "        \"number_assets\",\n",
    "        \"hhsize\",\n",
    "        \"young_children\",\n",
    "        \"working_age_adults\",\n",
    "        \"interest_rate\",\n",
    "    ],\n",
    "].corr()\n",
    "\n",
    "m_corr[\"interest_rate\"].round(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.11\n",
    "\n",
    "**Creating summary tables of means**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we use the `pd.crosstab` method to create the table with the variable `borrowed_from`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_10 = pd.crosstab(\n",
    "    got_l_c[\"borrowed_from\"],\n",
    "    got_l_c[\"rural\"],\n",
    "    margins=True,\n",
    "    normalize=\"columns\",\n",
    ").round(4)\n",
    "stab_10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in all settings, most loans come from relatives. To create the table with `borrowed_from_other`, substitute this variable name in the above command.\n",
    "\n",
    "Let's take a quick look at the loan lengths we expect (mean) when looking at the cross-tab between `rural` and `borrowed_from`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_10 = got_l_c.groupby([\"borrowed_from\", \"rural\"])[\"loan_length_abs\"].agg(\"mean\")\n",
    "tab_10.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the extra info on hours, so let's instead simplify this to only use full days. And we'll \"unstack\" the data to make it wider in format too, making it a bit more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_10.dt.days.unstack()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension: Investigating sources of finance associated with zero interest loans\n",
    "\n",
    "We previously saw that a large percentage of loans have a zero interest rate. Here we investigate whether particular sources of finance are responsible for these interest rates. The code we use is very similar to the code above, but instead of calculating the mean of a variable, we calculate the mean of a boolean (true/false) variable ((`interest_rate==0`)). This will deliver the proportion of `True` observations, in other words, loans where the interest rate was equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_11 = (\n",
    "    got_l_c.assign(rate_of_zero=lambda x: x[\"interest_rate\"] == 0)\n",
    "    .groupby([\"borrowed_from\", \"rural\"], dropna=False)\n",
    "    .agg(prop_0_interest=(\"rate_of_zero\", \"mean\"))\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "tab_11.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that in both urban and rural settings, a high proportion of loans granted by local merchants, neighbours, and relatives are zero interest (possibly because these people have a close relationship with the borrower so there is a lower chance of default).\n",
    "\n",
    "We will use exactly the same technique to determine the proportion of loans that go to households that report as being headed by a woman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_12 = (\n",
    "    got_l_c.assign(headed_by_woman=lambda x: x[\"gender\"] == \"Female\")\n",
    "    .groupby([\"borrowed_from\", \"rural\"], dropna=False)\n",
    "    .agg(prop_women=(\"headed_by_woman\", \"mean\"))\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "tab_12.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter used the following packages where *sys* is the Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26c4b888616894cf8360ee3d370b6a41732ef00c8f1d61e869c42a8428cf1ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
