{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Project 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Settings\n",
    "\n",
    "Let's import the packages we'll need and also configure the settings we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so  # installing seaborn installs this\n",
    "import pingouin as pg\n",
    "import warnings\n",
    "\n",
    "\n",
    "### You don't need to use these settings yourself\n",
    "### — they are just here to make the book look nicer!\n",
    "# Set the plot style for prettier charts:\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n",
    ")\n",
    "# Make seaborn work consistently with this\n",
    "so.Plot.config.theme.update(mpl.rcParams)\n",
    "# Ignore warnings to make nice output\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 10.1\n",
    "\n",
    "**Importing an Excel spreadsheet into Python**\n",
    "\n",
    "Before loading an Excel spreadsheet into Python, it can be helpful to open it in Excel to understand the structure of the spreadsheet and the data it contains. In this case we can see that detailed descriptions of all variables are in the first tab ('Definitions and Sources'). Make sure to read the definitions for the indicators listed in Figure 10.1.\n",
    "\n",
    "The spreadsheet contains a number of other worksheets, but the data that we need is in the tab called 'Data – June 2016'. You can see that the variable names are all in the first row and missing values are simply empty cells. We can therefore proceed to import the data into Python using the `pd.read_excel` function without any additional options.\n",
    "\n",
    "We're going to assume here that you've donwloaded the Excel file as \"GlobalFinancialDevelopmentDatabaseJune2017.xlsx\", and saved it in a subfolder of your working directory called \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfdd = pd.read_excel(\n",
    "    Path(\"data/GlobalFinancialDevelopmentDatabaseJune2017.xlsx\"),\n",
    "    sheet_name=\"Data - June 2016\",\n",
    ")\n",
    "gfdd.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 10.2\n",
    "\n",
    "**Making box and whisker plots**\n",
    "\n",
    "Box and whisker plots were introduced in Empirical Project 6. We can use the same process here, after ensuring that the data is in the correct format.\n",
    "\n",
    "Some plotting libraries expects data like we have ingested to be in ‘long’ (aka tidy) format (where each row is a value for a single variable and year), whereas our data is in ‘wide’ format (each row contains a single variable but multiple years). We transform the data from wide to long format using the\n",
    "\n",
    "So for the Depth indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience, create a list of the indicators we're interested in:\n",
    "indicators = [\"private_credit\", \"bank_assets\"]\n",
    "\n",
    "# Rename the variables we'll be plotting\n",
    "gfdd_new_names = gfdd.rename(\n",
    "    columns={\"GFDD.DI.01\": indicators[0], \"GFDD.DI.02\": indicators[1]}\n",
    ")\n",
    "\n",
    "# create a long or \"tidy\" version of the data & drop invalid values\n",
    "gfdd_long = gfdd_new_names.melt(\n",
    "    id_vars=[\"Country\", \"Year\"], value_vars=indicators, var_name=\"indicator\"\n",
    ").dropna()\n",
    "gfdd_long"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot it, which we'll do using the **seaborn** package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(data=gfdd_long, x=\"indicator\", y=\"value\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 10.2 Box and whisker plot for ‘Private credit by deposit money banks to GDP (%)’ (`private_credit`) and ‘Deposit money banks’ assets to GDP (%)’ (`bank_assets`).**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could repeat the process for each topic and plot all indicators together. However, the range for the `GFDD.AI.01` variable (Bank accounts per 1,000 adults) is far larger than the other variables in this group, so it makes sense to plot this separately. We use the same process as before, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience, create a list of the indicators we're interested in:\n",
    "indicators_big = [\"bank_accounts\"]\n",
    "\n",
    "# Rename the variables we'll be plotting\n",
    "gfdd_new_names = gfdd.rename(columns={\"GFDD.AI.01\": indicators_big[0]})\n",
    "\n",
    "# create a long or \"tidy\" version of the data & drop invalid values\n",
    "gfdd_long = gfdd_new_names.melt(\n",
    "    id_vars=[\"Country\", \"Year\"], value_vars=indicators_big, var_name=\"indicator\"\n",
    ").dropna()\n",
    "sns.boxplot(data=gfdd_long, x=\"indicator\", y=\"value\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to do this for a bunch more cases. A key principle of coding is 'DRY: Don't Repeat Yourself'. We shouldn't have to type this out multiple times, and it's more likely that something could go wrong if we do that. Instead, we're going to list all of the indicators in one go, and that's what the below code is going to do.\n",
    "\n",
    "However, we do need a trick for this. To change the names of the variables to sensible names we will use a built-in type of object in Python called a *dictionary*. Dictionaries provide a map from one set of values to another. A simple one might look like this:\n",
    "\n",
    "```python\n",
    "fruit_dict = {\n",
    "    \"Jazz\": \"Apple\",\n",
    "    \"Owari\": \"Satsuma\",\n",
    "    \"Seto\": \"Satsuma\",\n",
    "    \"Pink Lady\": \"Apple\",\n",
    "}\n",
    "```\n",
    "\n",
    "which maps varieties of fruit into types of fruit. A dictionary is super helpful here because we can use it to map the old column names to the new ones in a statement like `gfdd_new_names = gfdd.rename(columns=dict_of_new_names)`. When we're creating our dictionary below, we could do it like in the fruit example above, and there's nothing wrong with that. But for convenience, because we might use them later, we're going to instead create two lists (one for the new names and one for the old) and then bring those lists together to create our dictionary. We've already seen *list comprehensions* and the *zip* function; in the below we bring these ideas together to form a *dictionary comprehension* in the line:\n",
    "\n",
    "```python\n",
    "dict_of_new_names = {k: w for k, w in zip(old_names, indicators)}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience, create a list of the indicators we're interested in:\n",
    "indicators = [\n",
    "    \"private_credit\",\n",
    "    \"bank_assets\",\n",
    "    \"bank_accounts\",\n",
    "    \"bank_branches\",\n",
    "    \"firms_credit\",\n",
    "    \"small_firms_credit\",\n",
    "    \"risk_weighted_assets\",\n",
    "]\n",
    "\n",
    "# dictionary mapping old names to new names\n",
    "old_names = [\n",
    "    \"GFDD.DI.01\",\n",
    "    \"GFDD.DI.02\",\n",
    "    \"GFDD.AI.01\",\n",
    "    \"GFDD.AI.02\",\n",
    "    \"GFDD.AI.03\",\n",
    "    \"GFDD.AI.04\",\n",
    "    \"GFDD.SI.05\",\n",
    "]\n",
    "dict_of_new_names = {k: w for k, w in zip(old_names, indicators)}\n",
    "\n",
    "# Rename the variables we'll be plotting\n",
    "gfdd_new_names = gfdd.rename(columns=dict_of_new_names)\n",
    "\n",
    "# create a long or \"tidy\" version of the data & drop invalid values\n",
    "gfdd_long = gfdd_new_names.melt(\n",
    "    id_vars=[\"Country\", \"Year\"], value_vars=indicators, var_name=\"indicator\"\n",
    ").dropna()\n",
    "\n",
    "# put all of our indicators of interest into a box plot\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data=gfdd_long, y=\"indicator\", x=\"value\", ax=ax)\n",
    "ax.set_xlim(0, 1e3);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 10.4 Box and whisker plot for our indicators of interest**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat the process for the indicators on bank stability by copying the above code and adding indicator variable names accordingly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 10.3\n",
    "\n",
    "**Tabulating and visualizing time trends**\n",
    "\n",
    "In this walk-through we will use the indicators for ‘Deposit money banks’ assets to GDP (%)’ and ‘Bank accounts per 1,000 adults’ as examples (`bank_assets` and `bank_accounts` respectively).\n",
    "\n",
    "Obtaining the average indicator value for each year and region is straightforward using the `group_by` and `agg` functions, but again we have to select the relevant years (using `.query`) and remove any observations that have a missing value for the indicator being analysed (using `dropna`). We save the final output as `deposit_region`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_region = (\n",
    "    gfdd.rename(columns=dict_of_new_names)\n",
    "    .query(\"Year > 1999 & Year < 2015\")\n",
    "    .dropna(subset=[\"bank_assets\"])\n",
    "    .groupby([\"Year\", \"Region\"])[\"bank_assets\"]\n",
    "    .agg([\"mean\", \"count\"])\n",
    ")\n",
    "deposit_region"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage the summary data is stored in long format. This format is useful for plotting the data, but to produce the required table (with `Region` as the column variable and `Year` as the row variable), we need to reshape the data into wide format. While we previously used `melt` to move from wide to long, we can use the `pivot` function to achieve the opposite and transform the data from long to wide.\n",
    "\n",
    "There is a short-cut to `pivot` though: if we only wish to move one variable from a row to a column (and it is part of the index), we can simply use the `.unstack` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_region.unstack()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we get two sub-tables: one for mean, and one for count.\n",
    "\n",
    "At this point you could just print or view the data, however using one of many **pandas** export functions produces output that is visually easier to read and can be copied and pasted into your analysis document. Here are some examples with just the first few rows and just the first few columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to markdown, the popular text format\n",
    "print(deposit_region.iloc[:5, :3].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to latex, for writing papers\n",
    "print(deposit_region.iloc[:5, :3].style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to html, for the web\n",
    "print(deposit_region.iloc[:5, :3].to_html())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **seaborn** to plot a line chart using the long format data (`deposit_region`), with year on the horizontal axis. We specify `color = \"Region\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(deposit_region, x=\"Year\", y=\"mean\", color=\"Region\")\n",
    "    .add(so.Line(linewidth=2))\n",
    "    .label(\n",
    "        y=\"Mean deposit, % of GDP\",\n",
    "        title=\"Deposit money banks' assets to GDP (%), 2000-2014, by region\",\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 10.5 Line chart of ‘Deposit money banks’ assets to GDP (%)’, 2000–2014, by region.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process can be repeated for income group rather than region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_income = (\n",
    "    gfdd_new_names.query(\"Year > 1999\")\n",
    "    .dropna(subset=[\"bank_assets\"])\n",
    "    .groupby([\"Year\", \"Income Group\"])[\"bank_assets\"]\n",
    "    .agg([\"mean\", \"count\"])\n",
    ")\n",
    "\n",
    "(\n",
    "    so.Plot(deposit_income, x=\"Year\", y=\"mean\", color=\"Income Group\")\n",
    "    .add(so.Line(linewidth=2))\n",
    "    .label(\n",
    "        y=\"Mean deposit, % of GDP\",\n",
    "        title=\"Deposit money banks' assets to GDP (%), 2000-2014, by income group\",\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 10.6 Line chart of ‘Deposit money banks’ assets to GDP (%)’, 2000–2014, by income group.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat the process for the indicator 'Bank accounts per 1,000 adults' by replacing the variable name `bank_assets` with `bank_accounts` in the above code, again by region and then by income group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 10.4\n",
    "\n",
    "**Creating weighted averages**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we only require the weighted averages for the years 2004–2014, we will create a new dataframe (called `weighted_gfdd`) to save our results in. The weights are required for each country within each region for each year, but only if there is a value for the `GFDD.AI.01` (`bank_accounts`) indicator, so we:\n",
    " - filter results by years of interest using `.query`\n",
    " - select only columns of interest using `.loc`\n",
    " - drop any invalid entries for `bank_accounts` using `.dropna`\n",
    "\n",
    "With our new dataframe, we group by year and then region (using a `.groupby`) and then generate the weight for each country by dividing the population of each country by the sum of populations of all countries within a region (and year). To return the results in the same shape (index) as the data we began with, we use the `.transform` method. Remember:\n",
    "\n",
    "- Use `.agg` when using a groupby, but you want your groups to become the new index (here, this would give a year-region index)\n",
    "- Use `.transform` when using a groupby, but you want to retain your original index (here, numbered entries)\n",
    "- Use `.apply` when using a groupby, but you want to perform operations that will leave neither the original index nor an index of groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfdd_weighted = (\n",
    "    gfdd_new_names.query(\"Year > 2003 & Year < 2015\")\n",
    "    .loc[:, [\"Year\", \"Country\", \"Region\", \"bank_accounts\", \"SP.POP.TOTL\"]]\n",
    "    .dropna(subset=[\"bank_accounts\"])\n",
    ")\n",
    "\n",
    "gfdd_weighted[\"weight\"] = gfdd_weighted.groupby([\"Year\", \"Region\"])[\n",
    "    \"SP.POP.TOTL\"\n",
    "].transform(lambda x: x / x.sum())\n",
    "\n",
    "gfdd_weighted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we want to check that this actually works as weight! If it does, then summing over each year-region will produce a value of unity. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfdd_weighted.groupby([\"Year\", \"Region\"])[\"weight\"].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is correct, so we can proceed to calculate the required weighted indicator values by year and region. We start by creating a new variable with the weighted indicator value (`bank_accounts_weighted`), and then sum up the weighted indicator values by year and region. Recall that when calculating the weighted average, you sum all of the weighted observations rather than taking the mean (which would calculate the simple average instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gfdd_weighted.assign(\n",
    "        bank_accounts_weighted=lambda x: x[\"bank_accounts\"] * x[\"weight\"]\n",
    "    )\n",
    "    .groupby([\"Year\", \"Region\"])\n",
    "    .sum()\n",
    "    .round(2)[\"bank_accounts_weighted\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As ever, you can change this table by unstacking it, or just export it like this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 10.5\n",
    "\n",
    "**Dealing with extreme values**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use ‘Bank accounts per 1,000 adults’ (`bank_accounts`). The 95th and 5th percentiles can be obtained using the quantiles function. We save the output into a dataframe so we can refer to the values in later calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_5_95 = (\n",
    "    gfdd_new_names.query(\"Year == 2010\")\n",
    "    .dropna(subset=[\"bank_accounts\"])[\"bank_accounts\"]\n",
    "    .quantile([0.05, 0.95])\n",
    ")\n",
    "q_5_95"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the value of the indicator with these upper and lower bounds using the `np.where` function from numerical library **numpy**. The way `np.where` works is that it has the following syntax:\n",
    "\n",
    "```text\n",
    "np.where(condition, value if condition is true, value if condition is false)\n",
    "```\n",
    "\n",
    "But the beauty of `np.where` is that we need not just pass it single values in either of its three arguments: we can pass vectors to all of its arguments, creating a vector-valued return column. \n",
    "\n",
    "In the below, we make use of `np.where` to first replace all values below the 5th percentile with the value for the 5th percentile, and then to replace all values above the 95th percentile with the value for the 95th percentile.\n",
    "\n",
    "Gotcha warning! The index values for retrieving data from `q_5_95` are of integer type (as opposed to strings). Another gotcha! Because we refer to \"`bank_accounts`\" multiple times, we need to define it first in a separate step (or, alternatively use *lambda expressions*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfdd_2010 = gfdd_new_names.query(\"Year == 2010\").dropna(subset=[\"bank_accounts\"])\n",
    "\n",
    "bank_2010 = gfdd_2010.assign(\n",
    "    bank_accounts=np.where(\n",
    "        gfdd_2010[\"bank_accounts\"] < q_5_95[0.05],\n",
    "        q_5_95[0.05],\n",
    "        np.where(\n",
    "            gfdd_2010[\"bank_accounts\"] > q_5_95[0.95],\n",
    "            q_5_95[0.95],\n",
    "            gfdd_2010[\"bank_accounts\"],\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can obtain our summary statistics and print out the ‘Winsorized’ averages (use `gfdd_2010` to see the original averages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_2010.groupby(\"Income Group\").agg(avg_2010=(\"bank_accounts\", \"mean\")).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 10.6\n",
    "\n",
    "**Calculating confidence intervals**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python walkthroughs 3.6 and 8.10 we used the t-test function from the **pingouin** package to obtain differences in means and confidence intervals (CIs) for two groups of data. Here we need to obtain these statistics for the `GFDD.SI.05` indicator (renamed as `risk_weighted_assets`) between 2007 and 2014 for each region.\n",
    "\n",
    "As we need to find the confidence intervals for a number of regions, we can use a *vectorised operation* to perform the same calculation for each region in turn. For this, we do need to reshape our data, however. We want to make it so that the 2007 and 2014 values of risk weighted assets appear as columns while regions (and countries) are columns. To do this, we're going to first select both the values and variables we're interested in using the `.loc` command. We'll then use `pivot` to re-order the data into the shape we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwa_07_14 = gfdd_new_names.loc[\n",
    "    gfdd_new_names[\"Year\"].isin([2007, 2014]),\n",
    "    [\"Year\", \"Region\", \"Country\", \"risk_weighted_assets\"],\n",
    "].pivot(index=[\"Region\", \"Country\"], columns=[\"Year\"], values=[\"risk_weighted_assets\"])\n",
    "\n",
    "rwa_07_14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the shape, but we've unwittingly created quite a complex structure, especially of our index. To access columns in a hierarchical or multindex index, use a tuple (tuples have curvy brackets). You can see the precise name of the columns by running `.columns` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwa_07_14.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to get a t-test for each region. We'll use the **pingouin** package for the ttest, we'll groupby by region, and we'll use the apply function, which allows us to run functions that combine different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "rwa_07_14_ttest = rwa_07_14.groupby(\"Region\").apply(\n",
    "    lambda row: pg.ttest(\n",
    "        row[(\"risk_weighted_assets\", 2007)], row[(\"risk_weighted_assets\", 2014)]\n",
    "    )\n",
    ")\n",
    "rwa_07_14_ttest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explode out the confidence interval into two separate columns (it's one column of lists of two entries here). We'll also add in some other stats based on the t-test confidence intervals; the mean, and the width. Note that the mean is just the `.mean` across each row (`axis=1`), and the difference can be computed using `.diff` and then taking the one valid entry by using `dropna`.\n",
    "\n",
    "To assemble all of this, we're going to *concatenate* multiple dataframes using `pd.concat`. The syntax of this command is `pd.concat([list of dataframes], axis=<axis you want to stick dataframes together by)`. In the below, the two dataframes in our list are the original `rwa_07_14_ttest` and a new, second dataframe that we create in line that has the confidence intervals as its values and two columns, \"upper\" and \"lower\".\n",
    "\n",
    "Further below, when we wish to add in means and widths, we can do this by just declaring a new column (eg by writing `rwa_07_14_ttest[\"mean\"] = ...`) and then applying a function to the two columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwa_07_14_ttest = pd.concat(\n",
    "    [\n",
    "        rwa_07_14_ttest,\n",
    "        pd.DataFrame(\n",
    "            rwa_07_14_ttest[\"CI95%\"].tolist(),\n",
    "            columns=[\"lower\", \"upper\"],\n",
    "            index=rwa_07_14_ttest.index,\n",
    "        ),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "rwa_07_14_ttest[\"mean\"] = rwa_07_14_ttest[[\"lower\", \"upper\"]].mean(axis=1)\n",
    "rwa_07_14_ttest[\"width\"] = (\n",
    "    rwa_07_14_ttest[[\"lower\", \"upper\"]].diff(axis=1).dropna(axis=1) / 2\n",
    ")\n",
    "rwa_07_14_ttest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process can be repeated for income groups and for the indicator \"GFDD.SI.01\" (Bank Z-score)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 10.7\n",
    "\n",
    "**Plotting column charts with error bars**\n",
    "\n",
    "Again we use the `GFDD.SI.05` indicator (`risk_weighted_assets`) for Region as an example. You can repeat the following steps by region and for the `risk_weighted_assets` variable by changing the variable name(s) in Python walkthrough 10.6 accordingly, then running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so  # installing seaborn installs this\n",
    "\n",
    "(\n",
    "    so.Plot(\n",
    "        rwa_07_14_ttest.reset_index(),\n",
    "        y=\"Region\",\n",
    "        x=\"mean\",\n",
    "        color=\"Region\",\n",
    "        xmin=\"lower\",\n",
    "        xmax=\"upper\",\n",
    "    )\n",
    "    .add(so.Bar(edgecolor=\"k\"))\n",
    "    .add(so.Range(), so.Est(errorbar=\"ci\"))\n",
    "    .add(so.Dash(width=0.3), x=\"lower\")\n",
    "    .add(so.Dash(width=0.3), x=\"upper\")\n",
    "    .label(\n",
    "        title=\"Differences in risk weighted assets between 2007 and 2014\",\n",
    "        x=\"Difference\",\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 10.7 Column chart with error bars for ‘Bank regulatory capital to risk-weighted assets (%)’ (`risk_weighted_assets`).**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter used the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26c4b888616894cf8360ee3d370b6a41732ef00c8f1d61e869c42a8428cf1ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
