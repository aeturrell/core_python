{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Project 2 — Working in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Settings\n",
    "\n",
    "Let's import the packages we'll need and also configure the settings we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pingouin as pg\n",
    "from lets_plot import *\n",
    "\n",
    "LetsPlot.setup_html(no_js=True)\n",
    "\n",
    "### You don't need to use these settings yourself\n",
    "### — they are just here to make the book look nicer!\n",
    "# Set the plot style for prettier charts:\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1 Collecting data by playing a public goods game\n",
    "\n",
    "### Python Walkthrough 2.1\n",
    "\n",
    "**Plotting a line chart with multiple variables**\n",
    "\n",
    "Use the data from your own experiment to answer Question 1. As an example, we will use the data for the first three cities of the dataset that will be introduced in Part 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the data in\n",
    "data = {\n",
    "    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n",
    "    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n",
    "    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wish to plot the data. Note that, with data in \"wide\" format and with an index, simply calling `.plot` on a **pandas** dataframe will create a **matplotlib** line chart. We could also use the **lets-plot** package to make this kind of chart, but it expects data in \"tidy\" or \"long\" format—and for that, we would have to reshape the data so that the city names were values in a column called \"city\" or similar. Let's just run with **matplotlib** for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(ax=ax)\n",
    "ax.set_title(\"Average contribution to public goods game: without punishment\")\n",
    "ax.set_ylabel(\"Average contribution\")\n",
    "ax.set_xlabel(\"Round\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2.1** Average contributions in different locations.\n",
    "\n",
    "*Tip* When using **pandas**, there are several different types of bracket for accessing data values. Let's spell them out so that you know the differences. These are the different ways to get the first column of a dataframe (when that first column is called `column` and the dataframe is `df`):\n",
    "\n",
    "- `df.column`\n",
    "- `df[\"column\"]`\n",
    "- `df.loc[:, \"column\"]`\n",
    "- `df.iloc[:, 0]`\n",
    "\n",
    "Note that `:` means 'give me everything'! The ways to access rows are similar (here assuming the first row is called `row`):\n",
    "\n",
    "- `df.loc[\"row\", :]`\n",
    "- `df.iloc[0, :]`\n",
    "\n",
    "And to access the first value (ie the value in first row, first column):\n",
    "\n",
    "- `df.column[0]`\n",
    "- `df[\"column\"][0]`\n",
    "- `df.iloc[0, 0]`\n",
    "- `df.loc[\"row\", \"column\"]`\n",
    "\n",
    "In the above examples, square brackets are instructions about *where* to grab bits from the dataframe. They are a bit like an address system for values within a dataframe. Square brackets *also* denote lists though. So if you want to select *multiple* columns or rows, you might see syntax like this:\n",
    "\n",
    "`df.loc[[\"row0\", \"row1\"], [\"column0\", \"column2\"]]`\n",
    "\n",
    "which picks out two rows and two columns via the lists `[\"row0\", \"row1\"]` and `[\"column0\", \"column2\"]`. Because there are lists as well as the usual system of selecting values, there are two sets of square brackets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2 Describing the data\n",
    "\n",
    "### Python Walkthrough 2.2\n",
    "\n",
    "Both the tables you need are in a single Excel worksheet. Note down the cell ranges of each table, in this case A2:Q12 for the without punishment data and A16:Q26 for the punishment data. We will now use this range information to import the data into two dataframes (`data_n` and `data_p` respectively).\n",
    "\n",
    "In the below code, we'll use the `.copy` method, which we'll explain more about in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = pd.read_excel(\n",
    "    \"data/Public-goods-experimental-data.xlsx\",\n",
    "    usecols=\"A:Q\",\n",
    "    header=1,\n",
    "    index_col=\"Period\",\n",
    ")\n",
    "data_n = data_np.iloc[:10, :].copy()\n",
    "data_p = data_np.iloc[14:24, :].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading the data in Excel, you may see an error message about an \"unknown extension\". Note that this particular Excel file has some issues that mean **pandas** will warn you about an \"unknown extension\": an Excel file is actually a bundle of files tied up to look like one file, and what's happened here is that **pandas** doesn't recognise one of the files in the bundle—but we can still happily get at the data we need in the worksheets.\n",
    "\n",
    "In the code above, we used `.copy` and you may be wondering what it does. When a new object (say `data_p`) is created from an *existing* object (here `data_np`), programming languages have a few different options for how to do it. In this case, Python has two options: it could allocate some entirely new memory to store the new variable, `data_p`, or it could just create a link to the *existing* bit of memory where some of `data_np` is stored.\n",
    "\n",
    "The two different approaches behave differently. Under the former, changes to `data_p` won't affect `data_np` because `data_p` gets its own bit of memory and is entirely independent of the existing variable. But in the latter case, any changes to `data_p` will also be applied to `data_np`! This is because, underneath it all, they're both *pointing* to the same bit of computer memory. Indeed, that is why variables that do this are sometimes called *pointers*. They're common to most programming languages and **pandas** tends to use them by default because they save on memory—but this is just an example of a case where we don't want to change `data_np` by changing `data_p`, so we use the `.copy` method to allocate new memory and avoid creating a pointer.\n",
    "\n",
    "Let's see a simple example of how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    \"City A\": [14.1, 14.1, 13.7],\n",
    "    \"City B\": [11.0, 12.6, 12.1],\n",
    "}\n",
    "\n",
    "# Original dataframe\n",
    "test_df = pd.DataFrame.from_dict(test_data)\n",
    "# A copy of the dataframe\n",
    "test_copy = test_df.copy()\n",
    "# A pointer to the dataframe\n",
    "test_pointer = test_df\n",
    "\n",
    "\n",
    "test_pointer.iloc[1, 1] = 99"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now even though we only modified `test_pointer`, we can look at both the original data frame and the copy that we took earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_df=\")\n",
    "print(f\"{test_df}\\n\")\n",
    "print(\"test_copy=\")\n",
    "print(f\"{test_copy}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `test_df` has changed because `test_pointer` pointed to it, but our pure copy, `test_copy`, hasn't changed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as grabbing the data, we're going to ensure it is of the correct *datatype*. We can check the datatypes of the data we just read in using `data_n.info()` (you can do the same for `data_p`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns are of the \"object\" type, which is the default when it's not clear what datatype to use.\n",
    "\n",
    "We have continuous real numbers in the columns of `data_n` and `data_p` here, so we'll set the datatypes to be `double`, which is a datatype that does everything you'd expect for continuous real numbers (as opposed to the other widely used string, integer, and category datatypes, or any other datatype)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = data_n.astype(\"double\")\n",
    "data_p = data_p.astype(\"double\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data either by opening the dataframes from the Environment window or by typing `data_n` or `data_p` into the interactive Python window.\n",
    "\n",
    "You can see that in each row, the average contribution varies across countries; in other words, there is a distribution of average contributions in each period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Walkthrough 2.3\n",
    "\n",
    "**Calculating the mean using different methods**\n",
    "\n",
    "We calculate the mean using two different methods, to illustrate that there are usually many ways of achieving the same thing. We apply the first method on `data_n`, which uses the built-in `.mean()` function to calculate the average separately over each column except the first. We use the second method (the agg function) on `data_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_n_c = data_n.mean(axis=1)\n",
    "mean_p_c = data_p.agg(np.mean, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name suggests, the `agg` function applies an aggregation function (the mean function in this case) to all rows or columns in a dataframe. The second input, `axis=1`, applies the specified function to all rows in `data_p`. This is that we are averaging over cities (so cities no longer appears) for each period.\n",
    "\n",
    "Typing 0 would have calculated column means instead, ie it would have averaged over periods to produce one value per city (check and see for yourself). Type `help(pd.DataFrame.agg)` in your interactive Python window for more details, or see Python Walkthrough 2.5 for further practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the mean contribution**\n",
    "\n",
    "Now we will produce a line chart showing the mean contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "mean_n_c.plot(ax=ax, label=\"Without punishment\")\n",
    "mean_p_c.plot(ax=ax, label=\"With punishment\")\n",
    "ax.set_title(\"Average contribution to public goods game\")\n",
    "ax.set_ylabel(\"Average contribution\")\n",
    "ax.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2.2** Average contribution to public goods game, with and without punishment.\n",
    "\n",
    "The difference between experiments is stark, as the contributions increase and then stabilize at around 13 USD in the case where there is punishment, but decrease consistently from around 11 USD to 4 USD across the rounds when there is no punishment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Walkthrough 2.4\n",
    "\n",
    "**Drawing a column chart to compare two groups**\n",
    "\n",
    "To do this next part, we're going to make use of something called a \"list comprehension\", which is a special kind of loop. Loops are very useful in programming in the case where you have a competitive task that you want to execute while, for example, incrementing a number. You could use it to find the squares of the first 10 numbers, for example.\n",
    "\n",
    "A list comprehension is a way of writing a loop that creates a Python list. The loops it creates tend to be fast too.\n",
    "\n",
    "As a specific example, let's say we wanted to add the first name \"John\" to a list of names. Using a list comprehension this would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n",
    "[\"John \" + name for name in partial_names_list]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax here is square bracket (which usually signifies a list) then an operation (here `\"John\" + name`), and then `for thing in list`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a column chart, we will use the `.plot.bar()` function. We first extract the four data points we need (Periods 1 and 10, with and without punishment) and place them into another dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with bars in\n",
    "compare_grps = pd.DataFrame(\n",
    "    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n",
    "    index=[\"Without punishment\", \"With punishment\"],\n",
    ")\n",
    "# Rename columns to have \"round\" in them\n",
    "compare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n",
    "# flip cols and index round ready for plotting (.T is transpose)\n",
    "compare_grps = compare_grps.T\n",
    "# Make a bar chart\n",
    "compare_grps.plot.bar(rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2.3** Mean contributions in a public goods game.\n",
    "\n",
    "*Tip*: Experimenting with these charts will help you to learn how to use Python and its packages. Try using `.plot.bar(stacked=True)` or using `rot=45` as *keyword arguments*, or using `.plot.barh()` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Walkthrough 2.5\n",
    "\n",
    "**Calculating and understanding the standard deviation**\n",
    "\n",
    "In order to calculate these standard deviations and variances, we will use the agg function, which we introduced in Python Walkthrough 2.3. As we saw, `agg` is a command asking **pandas** to aggregate a set of rows or columns of the dataframe using a particular aggregation function. The basic structure is as follows: `df.loc[conditions or rows, columns].agg([function1, function2, ...])`. So to calculate the variances and more, we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\n",
    "n_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take `data_n` and apply the `\"var\"` and `\"std\"` functions to each row (recall that the second input 1 does this; 0 would indicate columns). Note that the index column, which contains the period numbers, is excluded from the calculation. The result is saved as a new variable called `n_c`.\n",
    "\n",
    "We then apply the same principle to of the `data_p` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: in the next chart, we will use another kind of loop. The syntax for this one is \"for thing in list of things\", then a colon (\":\"), then an indented operation that uses \"thing\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine whether 95% of the observations fall within two standard deviations of the mean, we can use a line chart. As we have 16 countries in every period, we would expect about one observation (0.05 × 16 = 0.8) to fall outside this interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "n_c[\"mean\"].plot(ax=ax, label=\"mean\")\n",
    "# mean + 2 sd\n",
    "(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n",
    "# mean - 2 sd\n",
    "(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\n",
    "for i in range(len(data_n.columns)):\n",
    "    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"Average contribution\")\n",
    "ax.set_title(\"Contribution to public goods game without punishment\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2.4** Contribution to public goods game without punishment.\n",
    "\n",
    "None of the observations fall outside the mean ± two standard deviations interval for the public goods game without punishment. Let’s see the equivalent chart for the version with punishment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "p_c[\"mean\"].plot(ax=ax, label=\"mean\")\n",
    "# mean + 2 sd\n",
    "(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n",
    "# mean - 2 sd\n",
    "(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\n",
    "for i in range(len(data_p.columns)):\n",
    "    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"Average contribution\")\n",
    "ax.set_title(\"Contribution to public goods game without punishment\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2.5** Contribution to public goods game with punishment.\n",
    "\n",
    "Here it looks as if we only have one observation outside the interval (in Period 8). In that aspect the two experiments look similar. However, from comparing these two charts, we see that the game with punishment displays a greater variation of responses than the game without punishment. In other words, there is a larger standard deviation and variance for the observations coming from the game with punishment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Walkthrough 2.6\n",
    "\n",
    "**Finding the minimum, maximum, and range of a variable**\n",
    "\n",
    "We're now going to see one of our first *functions*. A function takes inputs, does some operations on them, and returns outputs.\n",
    "\n",
    "You can imagine them a bit like vending machines: for it to work you need some inputs (money, and a choice of snack or drink), then an operation happens (your drink or snack is dropped into the tray), and finally there is an output (your drink or snack as you grab it).\n",
    "\n",
    "Functions are incredibly useful in programming because they are separate units that can be tested in isolation, re-used, and given helpful dressing (such as information on how they work) that make code more readable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the range for both experiments and for all periods, we will use an `apply` method in combination with the `max` and `min` methods that apply to a column or row. We'll also use a *lambda function* to bring these all together. In our case, it's going to look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p.apply(lambda x: x.max() - x.min(), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lambda function is saying take the difference between the maximum and minimum of each row.\n",
    "\n",
    "*Lambda functions* are an idea in programming (and mathematics) that has a long and interesting history. You don't need to know all that but it is instructive to look at a more general example of a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lambda function accepting three inputs, a,b and c and calculating the sum of the squares\n",
    "test_function = lambda a, b, c: a**2 + b**2 + c**2\n",
    "\n",
    "# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\n",
    "test_function(3, 4, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we defined a lambda function that looked like `lambda x: x.max() - x.min()`. It accepts one input `x` (which could be a row or column) and returns the range of `x`. Because making code re-usable is good programming practice, we will define this as a separate function and give it a name using a line of code like this:\n",
    "\n",
    "`range_function = lambda x: x.max() - x.min()`\n",
    "\n",
    "When we call `data_p.apply(range_function, axis=1)`, the following will happen: `data_p` contains the experimental data (with punishment). To that we will apply the `range_function`. As `data_p` has two dimensions, we also need to let Python know in over which dimension it should calculate the minimum and maximum. That is achieved by using the `axis=1` option in the apply function. This tells the apply function that it should apply the `range_function` over rows rather than columns (to get columns, it would be `axis=0`, which is also the default if you don't specify the axis keyword argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_function = lambda x: x.max() - x.min()\n",
    "range_p = data_p.apply(range_function, axis=1)\n",
    "range_n = data_n.apply(range_function, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a chart of the ranges for both experiments for all periods in order to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "range_p.plot(ax=ax, label=\"With punishment\")\n",
    "range_n.plot(ax=ax, label=\"Without punishment\")\n",
    "ax.set_ylim(0, None)\n",
    "ax.legend()\n",
    "ax.set_title(\"Range of contributions to the public goods game\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2.6** Range of contributions to public goods game.\n",
    "\n",
    "This chart confirms what we found in Python walkthrough 2.5, which is that there is a greater spread (variation) of contributions in the game with punishment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 2.7\n",
    "\n",
    "**Creating a table of summary statistics**\n",
    "\n",
    "We have already done most of the work for creating this summary table in Python walkthrough 2.7. Since we also want to display the minimum and maximum values, we should create these too. And it's convenient to pop in std and mean using the same syntax (even though we created a separate mean earlier). We'll call our new summary statistics `summ_p` and `summ_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\n",
    "summ_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"<lambda>\": \"range\"})\n",
    "summ_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"<lambda>\": \"range\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as well as applying all of the functions in the list `funcs_to_apply`, we also renamed the first function using the `rename` method. Because the range isn't a built-in aggregation function and we defined it, it is automatically given a column name——and because the range function we supplied is a lambda function, the name it gets is `\"<lambda>\"`. Using `rename(columns=`, we change this to `\"range\"` using a dictionary object that maps the old name to the new name.\n",
    "\n",
    "Now we display the summary statistics in a table. We use the `round` method, which reduces the number of digits displayed after the decimal point (`2` in our case) and makes the table easier to read. We're only interested in periods 1 and 10, so we pass a list, `[1, 10]`, to the `.loc` selector in the first position (which corresponds to rows and the index). We want all columns so we pass `:` to the second position of the `.loc` selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_n.loc[[1, 10], :].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can do the same for the version with punishment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_p.loc[[1, 10], :].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3 Describing the data\n",
    "\n",
    "### Python Walkthrough 2.8\n",
    "\n",
    "**Calculating the p-value for the difference in means**\n",
    "\n",
    "We need to extract the observations in Period 1 for the data for with and without punishment, and then feed the observations into a function that performs a t-test. We'll use the statistics package pingouin for this, which you will need to install on the command line using `pip install pingouin`. Once installed, import it using `import pingouin as pg`, just like we did at the start of the chapter.\n",
    "\n",
    "*Tip:* you can open up the command line, also known as the *terminal* or *command prompt*, in order to install packages in multiple ways.  If you're working within Visual Studio Code use the <kbd>⌃</kbd> + <kbd>\\`</kbd> keyboard shortcut (Mac) or <kbd>ctrl</kbd> + <kbd>\\`</kbd> (Windows and Linux), or click \"View > Terminal\". If you want to open up the command line independently of Visual Studio Code, search for “Terminal” on Mac and Linux, and “Anaconda Prompt” on Windows.\n",
    "\n",
    "**pingouin**'s t-test function is called `ttest`. The `ttest` function is extremely flexible: if you input two variables (x and y) as shown below, it will automatically test whether the difference in means is due to chance or not (formally speaking, it tests the null hypothesis that the means of both variables are equal).\n",
    "\n",
    "Note that the `ttest` function will only accept a series of data, not multiple data series. By subsetting to `iloc[1, :]`, we are passing in the 0th row (first period) for all columns (cities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as well as the T-statistic (`T`), the p-value (`p-val`), the degrees of freedom (`dof`), the alternative hypothesis (`two-sided`) and the confidence interval (`CI95%`), we get some other variables that help us put the main results into context.\n",
    "\n",
    "This result delivers a p-value of 0.9496. This means it is very likely that the assumption that there are no differences in the populations is likely to be true (formally speaking, we cannot reject the null hypothesis).\n",
    "\n",
    "The `ttest` function automatically assumes that both variables were generated by different groups of people. When calculating the p-value, it assumes that the observed differences are partly due to some variation in characteristics between these two groups, and not just the differences in experimental conditions. However, in this case, the same groups of people did both experiments, so there will not be any variation in characteristics between the groups. When calculating the p-value, we account for this fact with the `paired=True` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the p-value becomes smaller as we can attribute more of the differences to the ‘with punishment’ treatment, but the p-value is still very large (0.8828), so we still conclude that the differences in Period 1 are likely to be due to chance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter used the following packages where *sys* is the Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26c4b888616894cf8360ee3d370b6a41732ef00c8f1d61e869c42a8428cf1ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
