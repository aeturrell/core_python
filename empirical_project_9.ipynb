{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Project 9\n",
    "\n",
    "---\n",
    "**Download the code**\n",
    "\n",
    "To download the code used in this project as a notebook that can be run in Visual Studio Code, Google Colab, or Jupyter Notebook, right click [here]() and select 'Save Link As', then save it as a `.ipynb` file.\n",
    "\n",
    "Don’t forget to also download the data into your working directory by following the steps in this project.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting started in Python\n",
    "\n",
    "For this project, you will need the following packages:\n",
    "\n",
    "- **pandas** for data analysis\n",
    "- **matplotlib** for data visualisation\n",
    "- **numpy** for numerical methods\n",
    "- **statsmodels** for an extra statistics function\n",
    "\n",
    "You'll also be using the **warnings** and **pathlib** packages, but these come built-in with Python.\n",
    "\n",
    "Remember, you can install packages in Visual Studio Code's integrated terminal (click \"View > Terminal\") by running `conda install packagename` (if using the Anaconda distribution of Python) or `pip install packagename` if not.\n",
    "\n",
    "Once you have the Python packages installed, you will need to import them into your Python session—and configure any other initial settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "# Set the plot style for prettier charts:\n",
    "plt.style.use(\"plot_style.txt\")\n",
    "# Make output charts in 'svg' format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "# Ignore warnings to make nice output\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.1\n",
    "\n",
    "**Importing data into Python**\n",
    "\n",
    "Ensure that the Excel file you downloaded is in a sub-directory of your working directory called \"data\".\n",
    "\n",
    "Before importing the data, open it in Excel to look at its structure. You can see there are three tabs: ‘Data dictionary’, ‘All households’, and ‘Got loan’. We will import them into separate dataframes (data_dict, all_hh, and got_l respectively). We import the ‘Data dictionary’ so that we do not have to return to the Excel spreadsheet.\n",
    "\n",
    "Also note that there are a lot of empty cells, which is how missing data is coded in Excel (but not in Python). In the `pd.read_excel` function, the default is already that empty cell are read as NA, so we don't need to specify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.read_excel(\n",
    "    Path(\"data/doing-economics-working-in-excel-project-9-datafile.xlsx\"),\n",
    "    sheet_name=\"Data dictionary\",\n",
    ")\n",
    "\n",
    "all_hh = pd.read_excel(\n",
    "    Path(\"data/doing-economics-working-in-excel-project-9-datafile.xlsx\"),\n",
    "    sheet_name=\"All households\",\n",
    ")\n",
    "\n",
    "got_l = pd.read_excel(\n",
    "    Path(\"data/doing-economics-working-in-excel-project-9-datafile.xlsx\"),\n",
    "    sheet_name=\"Got loan\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s look at the variable types `all_hh` and `got_l` using the `.info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_l.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to ensure that all variables we expect to be numerical (numbers) show either int or float as their 'Dtype', and in this case, they are. You can see that there are many variables that are coded as object variables because they are text (for example gender or region), but since we can use these variables to group data by category, we will use `.astype(\"category\")` to change them into categorical variables for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of converting each object variable to a factor variable individually, we can use the `select_dtypes` method to find *all* columns that are currently of type object and then convert those columns specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = all_hh.select_dtypes(\"object\").columns\n",
    "all_hh[cols] = all_hh[cols].astype(\"category\")\n",
    "\n",
    "cols = got_l.select_dtypes(\"object\").columns\n",
    "got_l[cols] = got_l[cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making use of `.info()` will now show you that the remaining object columns have been \"recast\" to be of data type \"category\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.2\n",
    "\n",
    "**Creating summary tables**\n",
    "\n",
    "In order to get the proportions of households in each region living in large towns, small towns, or rural areas (encoded in the variable `rural`), we use the `pd.crosstab` function to create a cross-tabulation. Without any further options, `pd.crosstab` would produce counts of households in the respective regions and area types. However, we can pass a keyword argument, `normalize`, to turn the counts into proportions by, for example, rows or columns.\n",
    "\n",
    "In the below, we use `normalize=\"index\"` to ensure that each row sums to one. We also use `.round(3)` to limit the number of decimal places that are saved in the output data frame.\n",
    "\n",
    "Remember that if you ever want to know more about a function, you can hover over it in Visual Studio Code and see its options, including the keyword arguments it takes. Or you can run `help(function-name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_one = pd.crosstab(all_hh[\"region\"], all_hh[\"rural\"], normalize=\"index\").round(3)\n",
    "stab_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may not always want a cross-tab. For the case where we simply want an overall percentage, we can use \n",
    "\n",
    "Let’s use a similar approach to calculate the percentage of households with women as head of the family (encoded in the variable `gender`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_two = all_hh[\"gender\"].value_counts(normalize=True).round(3)\n",
    "stab_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, 30.4% of households have a head of the family who is a woman.\n",
    "\n",
    "We need to provide summary statistics for a range of variables. Most of these variables are numeric variables, but one, gender, is a categorical variable. We can distinguish these types using the `.select_dtypes` method.\n",
    "\n",
    "There are a few different ways to get summary statistics on a data frame. **pandas** has a built-in method called `.describe` which produces different information depending on whether the given columns are numeric or not. Here it is running on just numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh.select_dtypes(\"number\").describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use it on a categorical variable, `gender`, we get information relevant to that type of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh[\"gender\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are, of course, lots of different types of data. A more powerful summary of a data frame is provided by a packaged called **skimpy** (which you can install by running `pip install skimpy` on the command line). Here is **skimpy**'s `skim` function applied to `all_hh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import skim\n",
    "\n",
    "skim(all_hh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see lots of information on both the categorical and numeric data types!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.3\n",
    "\n",
    "**Making frequency tables for loan applications and outcomes**\n",
    "\n",
    "The easiest way to make a frequency table is to use the `pd.crosstab` function. Note that we use the `dropna=False` option (and \"All\" minus the sum of \"No\" and \"Yes\" gives the number of NAs), and the `margins=True` option to give those totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_three = pd.crosstab(\n",
    "    all_hh[\"did_not_apply\"], all_hh[\"loan_rejected\"], dropna=False, margins=True\n",
    ")\n",
    "stab_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do some data cleaning and re-examine the table. We:\n",
    "\n",
    "- exclude the households that indicated that they did not apply for a loan, but also indicated that they were refused a loan. This results in excluding more than 10% of households that indicated that they were refused a loan, but the answer is nonsensical. We will use the `~` operator, which means \"not\" the logic that follows.\n",
    "- We shall also remove all observations that have missing data for any of these two questions (by using the implicit default value of `dropna=True`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c = all_hh.loc[\n",
    "    ~(\n",
    "        (all_hh[\"loan_rejected\"] == \"Yes\")\n",
    "        & (all_hh[\"did_not_apply\"] == \"Did not apply\")\n",
    "    ),\n",
    "    :,\n",
    "]\n",
    "stab_four = pd.crosstab(\n",
    "    all_hh_c[\"did_not_apply\"], all_hh_c[\"loan_rejected\"], margins=True, normalize=\"all\"\n",
    ").round(3)\n",
    "stab_four"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.4\n",
    "\n",
    "**Creating variables to classify households**\n",
    "\n",
    "Let’s first create the `hh_status` variable. We set the values of `hh_status` to \"not applied\", then use logical indexing to change all entries where households applied for a loan (`all_hh_c[\"did_not_apply\"] == \"Applied\"`) and were accepted (`all_hh_c[\"loan_rejected\"] == \"No\"`) to \"successful\", and households who were denied (`all_hh_c[\"loan_rejected\"] == \"Yes\"`) to \"denied\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the default category and creates the new column\n",
    "all_hh_c[\"hh_status\"] = \"not applied\"\n",
    "\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"did_not_apply\"] == \"Applied\") & (all_hh_c[\"loan_rejected\"] == \"No\"),\n",
    "    \"hh_status\",\n",
    "] = \"successful\"\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"did_not_apply\"] == \"Applied\") & (all_hh_c[\"loan_rejected\"] == \"Yes\"),\n",
    "    \"hh_status\",\n",
    "] = \"denied\"\n",
    "\n",
    "# Change from a string variable to a categorical variable\n",
    "all_hh_c[\"hh_status\"] = all_hh_c[\"hh_status\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the frequencies of the different outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"hh_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will continue by using the same steps to make the `discouraged_borrower` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the default category and creates the new column\n",
    "all_hh_c[\"discouraged_borrower\"] = \"No\"\n",
    "\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"reason_not_apply1\"] == \"Believe Would Be Refused\"),\n",
    "    \"discouraged_borrower\",\n",
    "] = \"Yes\"\n",
    "all_hh_c.loc[\n",
    "    (all_hh_c[\"reason_not_apply2\"] == \"Believe Would Be Refused\"),\n",
    "    \"discouraged_borrower\",\n",
    "] = \"Yes\"\n",
    "\n",
    "# Change from a string variable to a categorical variable\n",
    "all_hh_c[\"discouraged_borrower\"] = all_hh_c[\"discouraged_borrower\"].astype(\"category\")\n",
    "\n",
    "all_hh_c[\"discouraged_borrower\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the `credit_constrained` variable, we use the `.cat.categories` property to check all the possible answers to the `reason_not_apply1` variable. We store these answers in the object `sel_ans`. (To convert from an index, a special type of **pandas** object, to a simple Python list, we put the expression on the right-hand side within a `list(..)`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_ans = list(all_hh_c[\"reason_not_apply1\"].cat.categories)\n",
    "sel_ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these reasons, only reasons 4 (Have Adequate Farm) and 7 (Other) do not lead to a conclusion that a household is credit constrained, so we remove them from `sel_ans`. Note that this numbering starts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_ans.remove(\"Have Adequate Farm\")\n",
    "sel_ans.remove(\"Other (Specify)\")\n",
    "sel_ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Households that did not provide any reasons are classified as *not* credit constrained. We'll take this as our default category and use it to create the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"credit_constrained\"] = \"No\"\n",
    "\n",
    "all_hh_c.loc[all_hh_c[\"reason_not_apply1\"].isin(sel_ans), \"credit_constrained\"] = \"Yes\"\n",
    "all_hh_c.loc[all_hh_c[\"reason_not_apply1\"].isin(sel_ans), \"credit_constrained\"] = \"Yes\"\n",
    "\n",
    "# let's turn this into a categorical variable\n",
    "all_hh_c[\"credit_constrained\"] = all_hh_c[\"credit_constrained\"].astype(\"category\")\n",
    "all_hh_c[\"credit_constrained\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of `.isin` in the selection criterion is a very useful programming technique that you can use to select data according to a list of variables. In this case, `sel_ans` contains all the answers that we associate with a credit-constrained household.\n",
    "\n",
    "`all_hh_c[\"reason_not_apply1\"].isin(sel_ans)` gives an outcome of `True` if the variable taken by an entry in the column `reason_not_apply1` is one of the values in `sel_ans`. In that case, it sets the value of `credit_constrained` to \"Yes\" for those observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_four = pd.crosstab(\n",
    "    all_hh_c[\"credit_constrained\"],\n",
    "    all_hh_c[\"discouraged_borrower\"],\n",
    "    margins=True,\n",
    "    normalize=\"all\",\n",
    ").round(3)\n",
    "stab_four"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the frequencies of the different reasons to not apply, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"reason_not_apply1\"].value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hh_c[\"reason_not_apply2\"].value_counts(normalize=True).round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 9.5\n",
    "\n",
    "**Making frequency tables to compare proportions**\n",
    "\n",
    "Some of the data is in the `all_hh` dataset, while the rest is in the `got_l` dataset, both of which we imported in Python Walkthrough 9.1. We will combine that information into one new dataset called `loan_data`, which we then use to produce the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_all_hh_c = all_hh_c.loc[all_hh_c[\"hh_status\"].isin([\"successful\", \"denied\"])]\n",
    "\n",
    "pd.crosstab(\n",
    "    sel_all_hh_c[\"loan_purpose\"], sel_all_hh_c[\"hh_status\"], normalize=\"columns\"\n",
    ").round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals a particular feature of the data, namely that for successful borrowers, the `all_hh_c` dataset does not contain all the useful information, as every successful household has \"Other (Specify)\" in the `loan_purpose` variable. There is more useful information on loan purpose in the `got_l` data, so we will extract the `loan_purpose` variable for unsuccessful households from the `all_hh_c` dataset, and the equivalent information for successful loaners from the `got_l` dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select unsuccessful households from allHHc\n",
    "loan_no <- subset(allHHc, allHHc$HH_status == \"denied\", \n",
    "  select = c(\"loan_purpose\", \"HH_status\"))\n",
    "\n",
    "# Select loan purpose for successful households from gotL\n",
    "loan_yes <- subset(gotL, gotL$got_loan == \"Yes\",\n",
    "  select = \"loan_purpose\")\n",
    "\n",
    "loan_yes$HH_status <- \"successful\"\n",
    "\n",
    "# Combine into one dataset\n",
    "loan_data <- rbind(loan_no, loan_yes)\n",
    "\n",
    "# Remove the unused 'did not apply' level\n",
    "loan_data <- droplevels(loan_data)\n",
    "\n",
    "kable(prop.table(table(\n",
    "  loan_data$loan_purpose, loan_data$HH_status,\n",
    "  dnn = c(\"Loan Purpose\", \"Loan\")), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unsuccessful households from all_hh_c\n",
    "loan_no = all_hh_c.loc[all_hh_c[\"hh_status\"] == \"denied\", [\"loan_purpose\", \"hh_status\"]]\n",
    "\n",
    "# Select loan purpose for successful households from gotL\n",
    "loan_yes = got_l.loc[got_l[\"got_loan\"] == \"Yes\", [\"loan_purpose\"]]\n",
    "loan_yes[\"hh_status\"] = \"successful\"\n",
    "\n",
    "# combine the data through concatenation\n",
    "loan_data = pd.concat([loan_yes, loan_no])\n",
    "\n",
    "# let's look at the values\n",
    "pd.crosstab(\n",
    "    loan_data[\"loan_purpose\"], loan_data[\"hh_status\"], normalize=\"columns\"\n",
    ").round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26c4b888616894cf8360ee3d370b6a41732ef00c8f1d61e869c42a8428cf1ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
