{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Project 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Settings\n",
    "\n",
    "Let's import the packages we'll need and also configure the settings we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import pingouin as pg\n",
    "import warnings\n",
    "\n",
    "\n",
    "### You don't need to use these settings yourself\n",
    "### — they are just here to make the book look nicer!\n",
    "# Set the plot style for prettier charts:\n",
    "plt.style.use(\"plot_style.txt\")\n",
    "# Make seaborn work consistently with this\n",
    "so.Plot.config.theme.update(mpl.rcParams)\n",
    "# Ignore warnings to make nice output\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 12.1\n",
    "\n",
    "**Importing a specified range of data from a spreadsheet**\n",
    "\n",
    "We start by importing the data; you will need to download it and put it in a subfolder of your working directory called \"data\". The data provided in the Excel spreadsheet is not in the usual format of one variable per column (known as ‘long’ format). Instead the first tab contains two separate tables, and we need the second table. We can therefore use the `skiprows=` keyword argument of **pandas**' `pd.read_excel` function to specify the cells in the spreadsheet to import (note that variable headers for the years are included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_excel(\n",
    "    Path(\"data/doing-economics-project-12-datafile.xlsx\"), skiprows=12\n",
    ")\n",
    "\n",
    "income"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still has some rows that we don't want in, so we need to get rid of them. There are multiple ways to do this depending on the context.\n",
    "\n",
    "In this case, we have two columns we don't want that have a large number of invalid entries in, so we can make use of the row-wise `.dropna()` method to clean up the data. While we're at it, let's rename the first column to something more sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.dropna(axis=0).rename(columns={\"Unnamed: 0\": \"Percentile\"})\n",
    "income"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be good to have a quick plot of this data. We'll need to re-orient if we want to make use of the **seaborn** plotting package (as this expects long-format data). We'll use `pd.melt` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(\n",
    "        pd.melt(\n",
    "            income, id_vars=\"Percentile\", value_vars=range(2009, 2016), var_name=\"Year\"\n",
    "        ),\n",
    "        x=\"Year\",\n",
    "        y=\"value\",\n",
    "        color=\"Percentile\",\n",
    "    )\n",
    "    .add(so.Line(linewidth=3))\n",
    "    .label(y=\"Monthly real household income (HKD)\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 12.1 Monthly real household income over time.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, plotting all percentile groups using the same scale hides a lot of variation within each percentile group. So, we should create a separate chart for each percentile group. As an example, we will plot the chart for the 15th percentile.\n",
    "\n",
    "First, we use the `pd.melt` function to reshape the data into the format that **seaborn** uses to plot charts. Then we use the `.loc` function to select data for the 15th percentile only. Finally, we can make the line chart as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_long = pd.melt(\n",
    "    income, id_vars=\"Percentile\", value_vars=range(2009, 2016), var_name=\"Year\"\n",
    ")\n",
    "\n",
    "perct_to_use = \"15th\"\n",
    "\n",
    "(\n",
    "    so.Plot(\n",
    "        income_long.loc[income_long[\"Percentile\"] == perct_to_use, :],\n",
    "        x=\"Year\",\n",
    "        y=\"value\",\n",
    "    )\n",
    "    .add(so.Line())\n",
    "    .add(so.Dot())\n",
    "    .label(y=f\"Monthly real household income for {perct_to_use} percentile\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 12.2 Monthly real household income for 15th percentile.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 12.2\n",
    "\n",
    "**Calculating cumulative income shares and plotting a Lorenz curve**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions 2(a)–(c) can be completed in one stage by method chaining, although there are a number of steps.\n",
    "\n",
    "First, we use the `.loc` method to get the relevant variables. Then, for the next step in the chain, we remove the ‘th’ suffix in the percentile column values using `.str.split(\"th\", expand=True)[0]` to split all the strings, expand the resulting list into two columns and, with `[0]`, only takes the first part (before the \"th\"). This is cast to an integer type.\n",
    "\n",
    "In the next step, we append on three zeros as the zeroth percentile entries for 2011 and 2012 (`.append`) followed by a sorting by percentile.\n",
    "\n",
    "We then do a number of operations on columns using `.assign`:\n",
    "\n",
    "- adding a column representing the number of households in each percentile group (assuming 100 households in the economy)\n",
    "- a new variable called `handout_2012` that adds $6,000 to each value for the year 2012\n",
    "- the economy-wide income for each percentile group, derived from multiplying the income values by the number of households and storing these in the variables `income_2011` and `income_2012`\n",
    "- then we need the normalised cumulative income for each group\n",
    "\n",
    "Finally we tidy up the data by ensuring that the 0th percentile has no share of the income and the 100th percentile has 100% of the cumulative income. We do this by adding a row of zero `.append` at the start `.sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = [\"Percentile\", 2011, 2012]\n",
    "\n",
    "income_shares = (\n",
    "    income.loc[:, cols_of_interest]\n",
    "    .assign(\n",
    "        Percentile=lambda x: x[\"Percentile\"]\n",
    "        .str.split(\"th\", expand=True)[0]\n",
    "        .astype(\"int\")\n",
    "    )\n",
    "    .append(pd.DataFrame([[0, 0, 0]], columns=cols_of_interest, index=[5]))\n",
    "    .sort_values(by=\"Percentile\")\n",
    "    .assign(\n",
    "        households=[15, 10, 25, 25, 10, 15],\n",
    "        handout_2012=lambda x: x[2012] + 6000,\n",
    "        income_2011=lambda x: x[2011] * x[\"households\"],\n",
    "        income_2012=lambda x: x[\"handout_2012\"] * x[\"households\"],\n",
    "        rel_share_2011=lambda x: 100\n",
    "        * x[\"income_2011\"].cumsum()\n",
    "        / x[\"income_2011\"].sum(),\n",
    "        rel_share_2012=lambda x: 100\n",
    "        * x[\"income_2012\"].cumsum()\n",
    "        / x[\"income_2012\"].sum(),\n",
    "        Percentile=lambda x: x[\"households\"] + x[\"Percentile\"],\n",
    "    )\n",
    "    .loc[:, [\"Percentile\", \"rel_share_2011\", \"rel_share_2012\"]]\n",
    "    .append(\n",
    "        pd.DataFrame(\n",
    "            [[0, 0, 0]],\n",
    "            columns=[\"Percentile\", \"rel_share_2011\", \"rel_share_2012\"],\n",
    "            index=[6],\n",
    "        )\n",
    "    )\n",
    "    .sort_values(by=\"Percentile\")\n",
    ")\n",
    "\n",
    "income_shares.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data from Questions 2(a)–(c) we can plot the Lorenz curve using the **seaborn** package. Note that we use the `Percentile` variable to draw the line of perfect equality.\n",
    "\n",
    "We will need to have data in long format for this, so do a melt,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "long_incomes_shares = pd.melt(\n",
    "    income_shares,\n",
    "    id_vars=\"Percentile\",\n",
    "    var_name=\"year\",\n",
    "    value_name=\"Cumulative share of income, %\",\n",
    ")\n",
    "\n",
    "p1 = (\n",
    "    so.Plot(\n",
    "        long_incomes_shares,\n",
    "        x=\"Percentile\",\n",
    "        y=\"Cumulative share of income, %\",\n",
    "        color=\"year\",\n",
    "    )\n",
    "    .add(so.Line())\n",
    "    .add(so.Dot())\n",
    "    .label(x=\"Cumulative share of population\")\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    long_incomes_shares[\"Percentile\"],\n",
    "    long_incomes_shares[\"Percentile\"],\n",
    "    linewidth=1.5,\n",
    "    alpha=0.5,\n",
    "    linestyle=\":\",\n",
    "    color=\"grey\",\n",
    ")\n",
    "p1.on(ax).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension Python Walkthrough 12.4\n",
    "\n",
    "**Converting nominal incomes to real incomes**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the real income values, we need to divide the income for each percentile group by the inflation index created in Question 5(a). Recall that we have only imported the real income data from the Excel spreadsheet and not the nominal income data, so we will first import the nominal income data (`nom_income`). Note that, in the code below, the inflation index is entered as a vector (list of numbers) called `inflation` (with the same number of elements as the number of years in the data) and this is multiplied (element-wise) by each row of the income data using the [todo] method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the nominal income data, drop everything beyond first table,\n",
    "# transpose, and set Percentile as the index\n",
    "nom_income = (\n",
    "    pd.read_excel(\n",
    "        Path(\"data/doing-economics-project-12-datafile.xlsx\"),\n",
    "        skiprows=2,\n",
    "    )\n",
    "    .loc[:4, :]\n",
    "    .set_index(\"Percentile\")\n",
    "    .T\n",
    ")\n",
    "\n",
    "nom_income"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we multiply through by the inflation data, taking the first element of the inflation data for the first row (excluding the year), the second for the second, and so on. Note that we actually need to divide by the inflation numbers, rather than multiply, which we do with a *list comprehension*. Finally, we transpose back to the original data shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation = [1, 1.024, 1.078, 1.122, 1.171, 1.222, 1.259, 1.289]\n",
    "nom_income = nom_income.mul([1 / num for num in inflation], axis=0).T\n",
    "nom_income.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 12.5\n",
    "\n",
    "**Importing data directly from a website, aka webscraping**\n",
    "\n",
    "Originally, this exercise downloaded data directly from the HKU POP website. It is no longer possible using the original code because the HKPOP website has changed. However, to demonstrate the principles, we'll webscrape some data from a table on Wikipedia.\n",
    "\n",
    "Webscraping is a way of grabbing information from the internet that was intended to be displayed in a browser. But it should only be used as a last resort, and only then when permitted by the terms and conditions of a website.\n",
    "\n",
    "If you're getting data from the internet, it's much better to use an API (application programming interface) whenever you can: grabbing information in a structured way is exactly why APIs exist. APIs should also be more stable than websites, which may change frequently. Typically, if an organisation is happy for you to grab their data, they will have made an API expressly for that purpose. It's pretty rare that there's a major website that does permit webscraping but which doesn't have an API; for these websites, if they don't have an API, chances are that scraping is against their terms and conditions. Those terms and conditions may be enforceable by law (there are different rules in different countries here, and you really need legal advice if it's not unambiguous as to whether you can scrape or not.)\n",
    "\n",
    "In Python, you are spoiled for choice when it comes to webscraping. There are five very strong libraries that cover a real range of user styles and needs: **requests**, **lxml**, **beautifulsoup**, **selenium**, and **scrapy**.\n",
    "\n",
    "For quick and simple webscraping, a combination of **requests** (which does little more than go and grab the HTML of a webpage) and **beautifulsoup**, which then helps you to navigate the structure of the HTML page, are good. However, in *this* example, we're going to see an even easier way, using **pandas**!\n",
    "\n",
    "We will read data from the first table on 'https://simple.wikipedia.org/wiki/FIFA_World_Cup' using **pandas**. Note that this method in **pandas** has a dependency on the **html5lib** package. The function we'll use is `read_html`, which returns a list of dataframes of all the tables it finds when you pass it a URL. If you want to filter the list of tables, use the `match=` keyword argument with text that only appears in the table(s) you're interested in.\n",
    "\n",
    "The example below shows how this works; looking at the website, we can see that the table we're interested in (of past world cup results), has a 'fourth place' column while other tables on the page do not. Therefore we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = pd.read_html(\n",
    "    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Fourth place\"\n",
    ")\n",
    "# Retrieve first and only entry from list of dataframes\n",
    "df = df_list[0]\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue on with the analysis in this section, head to the [PORI website](https://www.pori.hk), navigate to the POP Polls page, and then to the page on \"People’s Satisfaction with the HKSAR Government\". You should see some time series of polls. Switch to the half-yearly average tab and then scroll down. You can get the data from the \"Download CSV\" button.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 12.6\n",
    "\n",
    "**Cleaning imported data**\n",
    "\n",
    "Save the data in a subfolder called \"data\" with the filename (\"datatables.csv\" by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = pd.read_csv(\"Data/datatables.csv\")\n",
    "overall.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the data, the names of each column from the imported data are long and contain a mixture of alphabet sets. We also have many columns with percentage signs in, and (if you check using `overall.info()`) we have many columns with the wrong data types: \"object\" datatypes where we should have numeric datatypes, for example. We're going to clean up all of this in the next step.\n",
    "\n",
    "We usually rename variables using the `rename` method. However, in this case we'll just do a wholescale replacement of column names using the \"in-place\" operation `overall.columns = `.\n",
    "\n",
    "To remove all of those percentage and comma signs, we'll use a dataframe-wide `.replace` function with a dictionary mapping \"%\" and \",\" to \"\" (an empty string).\n",
    "\n",
    "And, for the data types, we'll map the dates to datetimes and all the other columns (from position 2 onwards) to float type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_names = [\n",
    "    \"start_date\",\n",
    "    \"end_date\",\n",
    "    \"cases\",\n",
    "    \"subsample\",\n",
    "    \"response_rate\",\n",
    "    \"very_satisfied\",\n",
    "    \"quite_satisfied\",\n",
    "    \"satisfied\",\n",
    "    \"half_half\",\n",
    "    \"quite_dissatisfied\",\n",
    "    \"very_dissatisfied\",\n",
    "    \"dissatisfied\",\n",
    "    \"dkhs\",\n",
    "    \"total\",\n",
    "    \"netvalue\",\n",
    "    \"meanvalue\",\n",
    "    \"base\",\n",
    "    \"meanerror\",\n",
    "]\n",
    "\n",
    "overall.columns = new_col_names\n",
    "\n",
    "overall = overall.replace({\"%\": \"\", \",\": \"\"}, regex=True)\n",
    "\n",
    "types_dict = {\n",
    "    \"start_date\": \"datetime64[ns]\",\n",
    "    \"end_date\": \"datetime64[ns]\",\n",
    "}\n",
    "types_dict.update({k: \"float\" for k in overall.columns[2:]})\n",
    "overall = overall.astype(types_dict)\n",
    "overall.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 12.7\n",
    "\n",
    "**Cleaning data and setting dates**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Question 3(a), before we can plot the imported data, any date variables need to be suitably formatted. We actually already did this in the previous step when we implicitly ran:\n",
    "\n",
    "```python\n",
    "overall[\"start_date\"] = overall[\"start_date\"].astype(\"datetime64[ns]\")\n",
    "```\n",
    "\n",
    "In general, the command for converting data in a column to datetime format, especially when they are less nice than in this case, is\n",
    "\n",
    "```python\n",
    "overall[\"start_date\"] = pd.to_datetime(overall[\"start_date\"])\n",
    "```\n",
    "\n",
    "For more knarly cases, you should look at the documentation for `pd.to_datetime`. Note that the standard format for dates is YYYY-MM-DD.\n",
    "\n",
    "Let's now plot this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(overall.query(\"start_date > 2006\"), x=\"start_date\", y=\"netvalue\")\n",
    "    .add(so.Line(linewidth=2))\n",
    "    .label(x=\"Date\", y=\"Net satisfaction\", title=\"Overall satisfication with HKSARG\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 12.7 Net public satisfaction with the government’s performance over time.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Question 3(b), in this example we use the variable \"Improving People's Livelihood\". Repeating the import and cleaning processes from Python walkthrough 12.5. In this case, we'll save it as \"satisfaction_datatables.csv\" in a sub-directory called \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement = pd.read_csv(\"Data/satisfaction_datatables.csv\")\n",
    "improvement = (\n",
    "    improvement.replace({\"%\": \"\", \",\": \"\"}, regex=True)\n",
    "    .dropna(axis=1)\n",
    "    .rename(columns={k: v for k, v in zip(improvement.columns, new_col_names)})\n",
    "    .astype(types_dict)\n",
    ")\n",
    "\n",
    "(\n",
    "    so.Plot(improvement.query(\"start_date > 2006\"), x=\"start_date\", y=\"netvalue\")\n",
    "    .add(so.Line(linewidth=2))\n",
    "    .label(\n",
    "        x=\"Date\",\n",
    "        y=\"Net satisfaction\",\n",
    "        title=\"HKSARG's Performance in Improving Livelihood\",\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 12.8 Net public satisfaction with the government’s ability to improve people’s livelihood over time.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter used the following packages where *sys* is the Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26c4b888616894cf8360ee3d370b6a41732ef00c8f1d61e869c42a8428cf1ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
