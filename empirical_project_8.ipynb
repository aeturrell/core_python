{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Project 8\n",
    "\n",
    "---\n",
    "**Download the code**\n",
    "\n",
    "To download the code used in this project as a notebook that can be run in Visual Studio Code, Google Colab, or Jupyter Notebook, right click [here]() and select 'Save Link As', then save it as a `.ipynb` file.\n",
    "\n",
    "Don’t forget to also download the data into your working directory by following the steps in this project.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting started in Python\n",
    "\n",
    "For this project, you will need the following packages:\n",
    "\n",
    "- **pandas** for data analysis\n",
    "- **matplotlib** for data visualisation\n",
    "- **numpy** for numerical methods\n",
    "\n",
    "You'll also be using the **warnings** and **pathlib** packages, but these come built-in with Python.\n",
    "\n",
    "Remember, you can install packages in Visual Studio Code's integrated terminal (click \"View > Terminal\") by running `conda install packagename` (if using the Anaconda distribution of Python) or `pip install packagename` if not.\n",
    "\n",
    "Once you have the Python packages installed, you will need to import them into your Python session—and configure any other initial settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Set the plot style for prettier charts:\n",
    "plt.style.use(\n",
    "    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n",
    ")\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 3]\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "\n",
    "# Ignore warnings to make nice output\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 8.1\n",
    "\n",
    "**Importing data into Python**\n",
    "\n",
    "As we are importing an Excel file, we use the `pd.read_excel` function provided by the **pandas** package. The file is called Project-8-datafile.xlsx and is saved into a subfolder of our working directory called 'data'. The file contains four worksheets that contain the data, named ‘Wave 1’ through to ‘Wave 4’. We will load the worksheets one-by-one and add them to the previous worksheets using the `pd.concat` function, which combines dataframes together. \n",
    "\n",
    "The final output is called `lifesat_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sheetnames = [\"Wave \" + str(i) for i in range(1, 5)]\n",
    "list_of_dataframes = [\n",
    "    pd.read_excel(Path(\"data/Project-8-datafile.xlsx\"), sheet_name=x)\n",
    "    for x in list_of_sheetnames\n",
    "]\n",
    "lifesat_data = pd.concat(list_of_dataframes, axis=0)\n",
    "lifesat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable names provided in the spreadsheet are not very specific (a combination of letters and numbers that don’t tell us what the variable measures). To make it easier to keep track we can use a multi-index for our columns; this is an index with more than one entry per column. We will create a multi-index that includes the original codes, then has labels, and then has a short description.\n",
    "\n",
    "Using a multi-index for columns does come with some downsides, as we'll see later.\n",
    "\n",
    "To create a multi-index, we're going to create a type of Python object called a `tuple`, which is like a list but has curvy brackets instead of square brackets. Tuples (curvy brackets) and lists (square brackets) are more similar than they are different, and you can use list or tuple comprehensions of the form `[x+1 for x in lots_of_xs]` to generate a list or `(x+1 for x in lots_of_xs)` to generate a tuple. The different is that lists are mutable: you can change them once they've been created. Tuples are immutable: once they've been created, they're frozen. Both types have their uses but multi-indexes and multi-layered columns in **pandas** use tuples.\n",
    "\n",
    "We'll zip up (using the `zip` function) the three lists of details: codenames (from the columns), labels, and short descriptions into a tuple. Each entry will look, for example, like `(\"A009\", \"Health\", \"State of health (subjective)\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"EVS-wave\",\n",
    "    \"Country/region\",\n",
    "    \"Respondent number\",\n",
    "    \"Health\",\n",
    "    \"Life satisfaction\",\n",
    "    \"Work Q1\",\n",
    "    \"Work Q2\",\n",
    "    \"Work Q3\",\n",
    "    \"Work Q4\",\n",
    "    \"Work Q5\",\n",
    "    \"Sex\",\n",
    "    \"Age\",\n",
    "    \"Marital status\",\n",
    "    \"Number of children\",\n",
    "    \"Education\",\n",
    "    \"Employment\",\n",
    "    \"Monthly household income\",\n",
    "]\n",
    "\n",
    "short_description = [\n",
    "    \"EVS-wave\",\n",
    "    \"Country/region\",\n",
    "    \"Original respondent number\",\n",
    "    \"State of health (subjective)\",\n",
    "    \"Satisfaction with your life\",\n",
    "    \"To develop talents you need to have a job\",\n",
    "    \"Humiliating to receive money w/o working for it\",\n",
    "    \"People who don't work become lazy\",\n",
    "    \"Work is a duty towards society\",\n",
    "    \"Work comes first even if it means less spare time\",\n",
    "    \"Sex\",\n",
    "    \"Age\",\n",
    "    \"Marital status\",\n",
    "    \"How many living children do you have\",\n",
    "    \"Educational level (ISCED-code one digit)\",\n",
    "    \"Employment status\",\n",
    "    \"Monthly household income (x 1,000s PPP euros)\",\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(\n",
    "    tuple(zip(lifesat_data.columns, labels, short_description)),\n",
    "    names=[\"code\", \"label\", \"description\"],\n",
    ")\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can replace the original columns with this multi-index, which is more informative than having the code names alone were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat_data.columns = index\n",
    "lifesat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is mostly for convenience, but we can still look at individual columns just as we did before (using the codes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat_data[\"S003\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this project we will refer to the variables using their original names, but you can see the extra info at the top of the dataframe when you need to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 8.2\n",
    "\n",
    "**Cleaning data and splitting variables**\n",
    "\n",
    "*Inspect the data and recode missing values*\n",
    "\n",
    "Python's **pandas** package stores variables as different types depending on the kind of information the variable represents. For categorical data, where, as the name suggests, data is divided into a number of groups, such as country or occupation, the variables can be stored as the `\"category\"`. Numerical data (numbers that do not represent categories) can be stored as integers, `\"int\"`, or real numbers, usually `\"double\"`. There are other datatypes too, for example `\"datetime64[ns]\"` for datetimes in nano-second increments. Text is of type `\"string\"`. There's also a 'not quite sure' datatype, `\"object\"`, which is typically used for data that doesn't clearly fall into a bucket.\n",
    "\n",
    "However, **pandas** is quite conservative about deciding on data types for you, so you do have to be careful to check the datatypes are what you want when they are read in. The classic example is of numbers being read in as type `\"object\"`.\n",
    "\n",
    "The `.info()` method tells us what data types are being used in a **pandas** dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of `\"object\"` columns, so it's clear that a lot of the columns haven't been read in as what they should be.\n",
    "\n",
    "Looking back at our data, we can see that there are a LOT of `\".a\"` values and, reading the original data source, it looks like these represent missing values. Let's replace those with the proper missing value indicator, `pd.NA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat_data = lifesat_data.replace(\".a\", pd.NA)\n",
    "lifesat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't the only way to deal with those pesky `\".a\"` values. When we read each file in, we could have replaced the value for missing data used in the file, `\".a\"`, with **pandas** built-in representation of missing numbers. This is achieved via the `na_values=\".a\"` keyword in the `pd.read_excel` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recode the life satisfaction variable*\n",
    "\n",
    "To recode the life satisfaction variable (`\"A170\"`), we can use a dictionary to map ‘Dissatisfied’ or ‘Satisfied’ into 1 or 10 respectively. This variable was imported as an object column. After changing the text into numerical values, we use the `astype(\"Int32\")` method to convert the variable into a 32-bit integer (these can represent any integer between -$2^{31}$ and $2^{31}$).\n",
    "\n",
    "Note that when using `.astype` below, we need to specify the complete column information (all three levels). This is so that when there's multiple columns beneath a higher level column, there isn't any ambiguity as to what the operation should be performed on. The extra complexity, which is avoid if you just have one layer of column names, is one disadvantage of multi-level column indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_tuple = (\"A170\", \"Life satisfaction\", \"Satisfaction with your life\")\n",
    "\n",
    "lifesat_data[col_name_tuple] = (\n",
    "    lifesat_data[col_name_tuple]\n",
    "    .replace({\"Satisfied\": 10, \"Dissatisfied\": 1})\n",
    "    .astype(\"Int32\")\n",
    ")\n",
    "lifesat_data[\"A170\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recode the variable for number of children*\n",
    "\n",
    "We repeat this process for the variable indicating the number of children (`\"X011_01\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_tuple = (\n",
    "    \"X011_01\",\n",
    "    \"Number of children\",\n",
    "    \"How many living children do you have\",\n",
    ")\n",
    "\n",
    "lifesat_data[col_name_tuple] = (\n",
    "    lifesat_data[col_name_tuple].replace({\"No children\": 0}).astype(\"Int32\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Replace text with numbers for multiple variables*\n",
    "\n",
    "When we have to recode multiple variables with the same mapping of text to numerical value, we can take a bit of a short-cut to recode multiple columns at once—even without writing out the full column names because we know, at least in our case, that we don't have any repeated columns at any level.\n",
    "\n",
    "To walk you through the trick, we're going to first take a column code name (the highest level), for example `\"C036\"`, and use that to recover the tuple (like a list but with curvy brackets instead of square ones) for the other two parts of the multi-column index like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_code = \"C036\"\n",
    "(column_code,) + lifesat_data[column_code].columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily pin-point every column, at all three levels, we wish to convert by creating a list of column-tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_codes = [\"C036\", \"C037\", \"C038\", \"C039\", \"C041\"]\n",
    "\n",
    "all_cols_at_all_levels = [\n",
    "    (column_code,) + lifesat_data[column_code].columns[0] for column_code in col_codes\n",
    "]\n",
    "\n",
    "lifesat_data[all_cols_at_all_levels] = (\n",
    "    lifesat_data[all_cols_at_all_levels]\n",
    "    .replace(\n",
    "        {\n",
    "            \"Strongly disagree\": 1,\n",
    "            \"Disagree\": 2,\n",
    "            \"Neither agree nor disagree\": 3,\n",
    "            \"Agree\": 4,\n",
    "            \"Strongly agree\": 5,\n",
    "        }\n",
    "    )\n",
    "    .astype(\"Int32\")\n",
    ")\n",
    "\n",
    "# This one needs a different mapping\n",
    "\n",
    "health_code = \"A009\"\n",
    "health_tuple = (health_code,) + lifesat_data[health_code].columns[0]\n",
    "lifesat_data[health_tuple] = (\n",
    "    lifesat_data[health_tuple]\n",
    "    .replace({\"Very poor\": 1, \"Poor\": 2, \"Fair\": 3, \"Good\": 4, \"Very good\": 5})\n",
    "    .astype(\"Int32\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Split a variable containing numbers and text*\n",
    "\n",
    "To split the education variable `\"X025A\"` into two new columns, we use the `.explode` method, which creates two new variables called Education_1 and Education_2 containing the numeric value and the text description respectively. Then we use the mutate_at function to convert Education_1 into a numeric variable.\n",
    "\n",
    "Because we're still using a multi-layered column system, we'll need to specify precise which combination of column names we're using in a tuple (as we just did above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_code = \"X025A\"\n",
    "educ_tuple = (education_code,) + lifesat_data[education_code].columns[0]\n",
    "new_col_a = educ_tuple\n",
    "lifesat_data[educ_tuple].str.split(\" : \", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this again but save it back into our dataframe under two new tuples. We'll pass these back in a list. First the tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_num_tuple = tuple(col + \"_num\" for col in educ_tuple)\n",
    "ed_sch_tuple = tuple(col + \"_school\" for col in educ_tuple)\n",
    "\n",
    "print(ed_num_tuple)\n",
    "print(ed_sch_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass them back in as a list (note the extra square brackets on the left-hand side) of tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat_data[[ed_num_tuple, ed_sch_tuple]] = (\n",
    "    lifesat_data[educ_tuple]\n",
    "    .str\n",
    "    .split(\" : \", expand=True)\n",
    ")\n",
    "lifesat_data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13950ff975ea58bb356510d0d8f98cdd1bd1f12bd4ccce66a17a21f4f1a23379"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('core-python-wDU3726x-py3.9': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
