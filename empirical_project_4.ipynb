{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Project 4\n",
    "\n",
    "## Python-specific learning objectives\n",
    "\n",
    "In addition to the learning objectives for this project, in this section you will learn how to convert (reshape) data from wide to long format and vice versa.\n",
    "\n",
    "## Getting started in Python\n",
    "\n",
    "TODO (list packages needed here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Go to the United Nations‚Äô [National Accounts Main Aggregates Database website](https://tinyco.re/7226184). On the right-hand side of the page, under ‚ÄòData Availability‚Äô, click ‚ÄòDownloads‚Äô.\n",
    "- Under the subheading ‚ÄòGDP and its breakdown at constant 2015 prices in US Dollars‚Äô, select the Excel file ‚ÄòAll countries for all years ‚Äì sorted alphabetically‚Äô.\n",
    "- Save it in a subfolder of the directory you are coding in such that that the relative path is `data/Download-GDPconstant-USD-all.xlsx`.\n",
    "\n",
    "## Python Walkthrough 4.1\n",
    "\n",
    "**Importing the Excel file (`.xlsx` or `.xls`) into Python**\n",
    "\n",
    "First, make sure you move the saved the data to a folder called `data` that is a subfolder of your working directory. The working directory is the folder that your code 'starts' in, and the one that you open when you start Visual Studio Code. Let's say you called it `core`, then the file and folder structure of your working directory would look like this:\n",
    "\n",
    "```bash\n",
    "üìÅ core\n",
    "‚îÇ‚îÄ‚îÄüìÅdata\n",
    "   ‚îî‚îÄ‚îÄDownload-GDPconstant-USD-all.xlsx\n",
    "‚îÇ‚îÄ‚îÄempirical_project_4.py\n",
    "```\n",
    "\n",
    "This is similar to what you should see in Visual Studio Code under the explorer tab (although the working directory, `core`, won't appear). You can check your working directory by running\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.getcwd()\n",
    "```\n",
    "\n",
    "in Visual Studio Code.\n",
    "\n",
    "Next, we need to import the packages and settings we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Set the plot style for prettier charts:\n",
    "plt.style.use(\n",
    "    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n",
    ")\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 3]\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "theme_set(theme_seaborn)\n",
    "\n",
    "# Ignore warnings to make nice output\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before importing the file into Python, open the file in Excel, OpenOffice, LibreOffice, or Numbers to see how the data is organized in the spreadsheet, and note that:\n",
    "\n",
    "- There is a heading that we don‚Äôt need, followed by a blank row.\n",
    "- The data we need starts on row three.\n",
    "\n",
    "Armed with this knowledge, we can import the data using the `Path` module to create the path to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(Path(\"data/Download-GDPconstant-USD-all.xlsx\"), skiprows=2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 4.2\n",
    "\n",
    "**Making a frequency table**\n",
    "\n",
    "We want to create a table showing how many years of `Final consumption expenditure` data are available for each country.\n",
    "\n",
    "Looking at the dataset‚Äôs current format, you can see that countries and indicators (for example, `Afghanistan` and `Final consumption expenditure`) are row variables, while year is the column variable. This data is organized in ‚Äòwide‚Äô format (each individual‚Äôs information is in a single row).\n",
    "\n",
    "For many data operations and making charts it is more convenient to have indicators as column variables, so we would like `Final consumption expenditure` to be a column variable, and year to be the row variable. Each observation would represent the value of an indicator for a particular country and year. This data is organized in ‚Äòlong‚Äô format (each individual‚Äôs information is in multiple rows). This is also called 'tidy' data and it can be recognised by having variable per column and one observation per row. Many data scientists consider keeping data in tidy format good practice.\n",
    "\n",
    "To change data from wide to long format, we use the `pd.melt` method. The `melt` method is very powerful and useful, as you will find many large datasets are in wide format. In this case, `pd.melt` takes the data from all columns not specified as being `id_vars` (via a list of column names), and uses them to create two new columns: one contains the name of the row variable created from the former column names, which is the year here; we can set that new column's name with `var_name=\"year\"`. The second new column contains the values that were in the columns we unpivoted and is automatically given the name `value`. (We could have set a new name for this column by passing `value_name=` too.)\n",
    "\n",
    "Compare `df_long` to the wider `df` to understand how the melt command works. To learn more about organizing data in Python, see the [Working with Data](https://aeturrell.github.io/coding-for-economists/data-intro.html) section of 'Coding for Economists'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.melt(\n",
    "    df, id_vars=[\"Area/CountryID\", \"Area/Country\", \"IndicatorName\"], var_name=\"year\"\n",
    ")\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the required table, we only need `Final consumption expenditure` of each country, which we extract using the `.loc` function. We'd like all columns so we pass the condition in the first position of `.loc` and leave the second entry as `:` for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = df_long.loc[df_long[\"IndicatorName\"] == \"Final consumption expenditure\", :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_count = cons.groupby(\"Area/Country\").agg(available_years=(\"year\", \"count\"))\n",
    "year_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating the code in words: Take the variable `cons` and group the observations by area and country (`.groupby(Area/Country\")`), then take this result and aggregate `.agg` it such that a new variable called available years (`available_years=`) is created that sees the column year counted (`(\"year\", \"count\")`).\n",
    "\n",
    "Now we can establish how many of the 250 countries and areas in the dataset have complete information. A dataset is complete if it has the maximum number of available observations (given by `year_count[\"available_years\"].max()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(year_count[\"available_years\"] == year_count[\"available_years\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the full set of data are available for all countries and areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 4.3\n",
    "\n",
    "**Creating new variables**\n",
    "\n",
    "We will use Brazil, the US, and China as examples.\n",
    "\n",
    "Before we select these three countries, we will calculate the net exports (exports minus imports) for all countries, as we need that information in Python walkthrough 4.4. We will also shorten the names of the variables we need, to make the code easier to read. We will use a dictionary to map names into shorter formats. A dictionary is a built-in object type in Python and always has the structure `{key1: value1, key2: value2, ...}` where the keys and values could have any type (eg string, int, dataframe). In our case, both keys and values will be strings. We will use a convention for our naming that is known as \"snake case\". This means all lower case with spaces replaced by underscores (it looks a bit like a snake!). There are packages that will auto-rename long variables for you, but let's see how to do it manually here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_names_dict = {\n",
    "    \"Final consumption expenditure\": \"final_expenditure\",\n",
    "    \"Household consumption expenditure (including Non-profit institutions serving households)\": \"hh_expenditure\",\n",
    "    \"General government final consumption expenditure\": \"gov_expenditure\",\n",
    "    \"Gross capital formation\": \"capital\",\n",
    "    \"Imports of goods and services\": \"imports\",\n",
    "    \"Exports of goods and services\": \"exports\",\n",
    "}\n",
    "# rename these values\n",
    "df_long[\"IndicatorName\"] = df_long[\"IndicatorName\"].replace(short_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_long` still has several rows for a particular country and year (one for each indicator). We will reshape this data using the `.pivot` method to ensure that we have only one row per country/area and per year. Note that `pivot` preserves the list of columns we pass as the `index=` and pivots the columns we pass to `columns=` out so that they are wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = df_long.pivot(\n",
    "    index=[\"Area/CountryID\", \"Area/Country\", \"year\"], columns=[\"IndicatorName\"]\n",
    ")\n",
    "df_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a `net_exports` column based on the existing columns (exports - imports), and we can know that this will be a unique country/area and year combination for each row. First we need to drop the top level of the column index, which is currently called `value`: we don't need this anymore. This will allow for direct access to the `exports` and `imports` columns. We'll also reset the index to row numbers rather than those three columns we used in the pivot. We'll also remove the name of the columns as we won't need that any longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table.columns = df_table.columns.droplevel()\n",
    "df_table = df_table.reset_index()\n",
    "df_table.columns.name = \"\"\n",
    "df_table[\"net_exports\"] = df_table[\"exports\"] - df_table[\"imports\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us select our three chosen countries to check that we calculated net exports correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_countries = [\"Brazil\", \"United States\", \"China\"]\n",
    "cols_to_keep = [\"Area/Country\", \"year\", \"exports\", \"imports\", \"net_exports\"]\n",
    "\n",
    "df_sel_un = df_table.loc[df_table[\"Area/Country\"].isin(sel_countries), cols_to_keep]\n",
    "df_sel_un.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 4.4\n",
    "\n",
    "**Plotting and annotating time series data**\n",
    "\n",
    "*Extract the relevant data*\n",
    "\n",
    "We will work with the `df_long` dataset, as the long format is well suited to produce charts with the **seaborn** package. In this example, we use the US and China (which we will now save as the dataframe `comp`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a copy of df_long that is just US and China\n",
    "comp = df_long.loc[df_long[\"Area/Country\"].isin([\"United States\", \"China\"]), :].copy()\n",
    "# Convert value to billion USD\n",
    "comp[\"value\"] = comp[\"value\"] / 1.0e9\n",
    "# Filter down to certain cols and values\n",
    "comp = comp.loc[\n",
    "    comp[\"IndicatorName\"].isin(\n",
    "        [\"gov_expenditure\", \"hh_expenditure\", \"capital\", \"imports\", \"exports\"]\n",
    "    ),\n",
    "    [\"Area/Country\", \"year\", \"IndicatorName\", \"value\"],\n",
    "]\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot a line chart*\n",
    "\n",
    "We can now plot this data using the **seaborn** data visualisation library. We'll subset to US' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data=comp[comp[\"Area/Country\"] == \"United States\"],\n",
    "    x=\"year\",\n",
    "    y=\"value\",\n",
    "    hue=\"IndicatorName\",\n",
    "    style=\"IndicatorName\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 4.2 The US‚Äôs GDP components (expenditure approach).*\n",
    "\n",
    "There are plenty of problems with this chart:\n",
    "\n",
    "- the vertical axis label is uninformative\n",
    "- there is no chart title\n",
    "- the y-axis dips below zero\n",
    "- the legend is uninformative.\n",
    "\n",
    "\n",
    "To improve this chart, we add features to the figure by creating the axis, `ax`, explicitly. We'll also use a trick where we invert the dictionary from earlier and use this to supply full names to the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO finalise\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    data=comp[comp[\"Area/Country\"] == \"United States\"],\n",
    "    x=\"year\",\n",
    "    y=\"value\",\n",
    "    hue=\"IndicatorName\",\n",
    "    style=\"IndicatorName\",\n",
    "    ax=ax,\n",
    ")\n",
    "# Set sensible y-lims\n",
    "ax.set_ylim(0, 1.4e4)\n",
    "# Add a y-label\n",
    "ax.set_ylabel(\"Billions USD\")\n",
    "# Add a title\n",
    "ax.set_title(\"GDP components over time\", loc=\"center\")\n",
    "# Add an annotation for a feature at a specific year\n",
    "ax.annotate(\"Great Recession\", (2008, 0.05e4), size=8, ha=\"center\")\n",
    "# Use full number notation\n",
    "ax.ticklabel_format(style=\"plain\")\n",
    "# Tweak the legend\n",
    "# first reverse the dictionary and only keep words before \"(\"\n",
    "rev_name_dict = {v: k.split(\"(\")[0] for k, v in short_names_dict.items()}\n",
    "# now set the legend with new labels by getting old labels (`ax.get_legend_handles_labels()[1]`) and\n",
    "# converting them back to original column names\n",
    "ax.legend(\n",
    "    frameon=False,\n",
    "    fontsize=8,\n",
    "    labels=[rev_name_dict[x] for x in ax.get_legend_handles_labels()[1]],\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Figure 4.3** The US‚Äôs GDP components (expenditure approach), amended chart.*\n",
    "\n",
    "We can make a chart for more than one country simultaneously by switching to a **seaborn** `relplot` with otherwise the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO finalise\n",
    "rel = sns.relplot(\n",
    "    data=comp,\n",
    "    kind=\"line\",\n",
    "    style=\"IndicatorName\",\n",
    "    x=\"year\",\n",
    "    y=\"value\",\n",
    "    hue=\"IndicatorName\",\n",
    "    col=\"Area/Country\",\n",
    "    linewidth=2.5,\n",
    ")\n",
    "rev_name_dict = {v: k.split(\"(\")[0] for k, v in short_names_dict.items()}\n",
    "\n",
    "\n",
    "for ax in rel.fig.axes:\n",
    "    ax.set_ylim(0, 1.4e4)\n",
    "    # Use full number notation\n",
    "    ax.ticklabel_format(style=\"plain\")\n",
    "\n",
    "# Change name in legend\n",
    "[t.set_text(rev_name_dict[t.get_text()]) for t in rel._legend.texts]\n",
    "\n",
    "rel.fig.axes[0].set_ylabel(\"Billions USD\")\n",
    "# remove default legend\n",
    "rel._legend.remove()\n",
    "# add custom legend\n",
    "rel.fig.axes[0].legend(\n",
    "    frameon=False,\n",
    "    fontsize=8,\n",
    "    labels=[rev_name_dict[x] for x in rel.fig.axes[0].get_legend_handles_labels()[1]],\n",
    ")\n",
    "plt.suptitle(\"GDP components over time\", y=1.03);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO finalise\n",
    "pl = (\n",
    "    ggplot(comp, aes(x=\"year\", y=\"value\", color=\"IndicatorName\"))\n",
    "    + geom_line(aes(group=\"IndicatorName\"), size=1)\n",
    "    + facet_wrap(\"Area/Country\")\n",
    "    + scale_y_continuous(name=\"Billion US$\")\n",
    "    + theme(theme_bw)\n",
    "    + scale_x_discrete(breaks=range(comp[\"year\"].min(), comp[\"year\"].max(), 10))\n",
    "    + scale_colour_discrete(\n",
    "        name=\"Components of GDP\",\n",
    "        labels=[rev_name_dict[x] for x in sorted(comp[\"IndicatorName\"].unique())]\n",
    "    )\n",
    ")\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Figure 4.4** GDP components over time (China and the US).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Walkthrough 4.5\n",
    "\n",
    "**Calculating new variables and plotting time series data**\n",
    "\n",
    "*Calculate proportion of total GDP*\n",
    "\n",
    "We will use the `comp` dataset created in Python Walkthrough 4.4. First we will calculate net exports, as that contributes to GDP. As the data is currently in long format, we will reshape the data into wide format so that the variables we need are in separate columns instead of separate rows (using the `pivot` method, as in Python Walkthrough 4.3), calculate net exports, then transform the data back into long format using the `melt` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to wide format (indicators in columns)\n",
    "comp_wide = comp.pivot(index=[\"Area/Country\", \"year\"], columns=\"IndicatorName\")\n",
    "comp_wide.columns = comp_wide.columns.droplevel()\n",
    "comp_wide.columns.name = \"\"\n",
    "comp_wide = comp_wide.reset_index()\n",
    "comp_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the new column for net exports = exports ‚Äì imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_wide[\"net_exports\"] = comp_wide[\"exports\"] - comp_wide[\"imports\"]\n",
    "comp_wide.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13950ff975ea58bb356510d0d8f98cdd1bd1f12bd4ccce66a17a21f4f1a23379"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('core-python-wDU3726x-py3.9': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
